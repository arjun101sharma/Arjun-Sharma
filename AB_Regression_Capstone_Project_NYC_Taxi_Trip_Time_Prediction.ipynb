{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjun101sharma/Arjun-Sharma/blob/main/AB_Regression_Capstone_Project_NYC_Taxi_Trip_Time_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - NYC Taxi Trip Time Prediction.\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Project Type**    - Regression.\n",
        "#### **Contribution**    - Individual.\n",
        "#### **Team Member 1**-  $\\color{red}{\\text{Arjun Sharma}}$"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**\n",
        "\n",
        "\n",
        "**Data Preprocessing** :\n",
        "\n",
        "1. Getting the dataset\n",
        "2. Importing libraries\n",
        "3. Importing datasets\n",
        "4. Finding Missing Data\n",
        "5. Encoding Categorical Data\n",
        "6. Data Cleaning and Feature Engineering\n",
        "\n",
        "**Exploratory data analysis(EDA) :**\n",
        "\n",
        "1. The distribution of Number of Pickups and Dropoffs on each part of the day.\n",
        "\n",
        "2. A line plot for the relationship between 'pickup_month' and 'trip_duration'.\n",
        "\n",
        "3. Distribution of number of Pickups During 24 Hours.\n",
        "\n",
        "4. Grouping the data in the 'taxi_df' DataFrame by \"pickup_month\" and \"vendor_id\".\n",
        "\n",
        "5. Create a count plot using seaborn, using the \"passenger_count\" column from the dataset.\n",
        "\n",
        "6. Group the data by the categorized trip durations and count the number of trips in each category.\n",
        "\n",
        "7. For visually comparing the distributions and central tendencies (mean and median) of different numeric features in the \"taxi_df\" DataFrame using histograms and box plots.Iterate through each numeric feature in the DataFrame.\n",
        "\n",
        "8. **Correlation Heatmap** - Generates a heatmap to visualize the correlation matrix of the NYC Taxi Trip Time Prediction dataset.\n",
        "\n",
        "9. **Pair Plot**- A pair plot is a grid of scatterplots, where variables are plotted against each other. If you have a dataset with multiple numeric variables, a pair plot allows you to visualize the relationships between these variables.\n",
        "\n",
        "\n",
        "\n",
        "**Supervised Regression Machine learning algorithms and implementation :**\n",
        "\n",
        " XG Boost.\n",
        "\n",
        " Random Forest.\n",
        "\n",
        " Decision Tree.\n",
        "\n",
        " Gradient Boost.\n",
        "\n",
        " Linear Regressor."
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Summary:** Predicting NYC Taxi Trip Time Duration\n",
        "\n",
        "The NYC Taxi Time Prediction project aimed to forecast the duration of taxi trips in New York City, leveraging a comprehensive dataset comprising factors like pickup/dropoff locations, time of day, and weather conditions. This regression-focused endeavor employed machine learning techniques to create a robust predictive model.\n",
        "\n",
        "**Data and Features:**\n",
        "The project utilized a diverse dataset encompassing over 1.5 million taxi trips. Various features were employed in the regression model, including distance, pickup and dropoff coordinates, pickup datetime, day of the week, and weather conditions like temperature, precipitation, and wind speed.\n",
        "\n",
        "**Methodology:**\n",
        "The dataset was randomly split into training and testing sets to facilitate model training and evaluation. Several machine learning algorithms, including Linear Regression, Decision Trees, Random Forest, Gradient Boosting, and XGBoost, were explored. The model's performance was assessed using metrics like Mean Squared Error (MSE), Root Mean Squared Error (RMSE), R2 Score, and Adjusted R2 Score.\n",
        "\n",
        "**Results:**\n",
        "The regression model emerged as the top performer, surpassing other algorithms in accuracy. It achieved an impressive R2 score of 67%, indicating its strong predictive capabilities. The model's accuracy was further validated through comparisons with alternative machine learning approaches.\n",
        "\n",
        "**Conclusion:**\n",
        "The NYC Taxi Time Prediction project showcased the potential of regression models in accurately forecasting taxi trip durations. By leveraging a combination of location data, temporal information, and weather conditions, the model demonstrated its effectiveness in capturing the complexities of New York City taxi journeys. This project not only highlights the power of predictive analytics in the transportation sector but also underscores the significance of feature selection and algorithm choice in enhancing prediction accuracy."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement:**\n",
        "\n",
        "The New York City (NYC) Taxi Trip Time Duration prediction project faces several challenges and observations that require careful consideration and strategic solutions. The primary concerns include the presence of outliers in the dataset, potential overfitting of models, and the impact of data removal on model performance.\n",
        "\n",
        "1. **Outlier Management:**\n",
        "   The dataset exhibits a substantial presence of outliers, some of which are very close to zero. Attempting to remove these outliers resulted in significant data loss, impacting the overall dataset integrity. The challenge lies in effectively managing these outliers without compromising the dataset's size and quality.\n",
        "\n",
        "2. **Model Overfitting:**\n",
        "   Concerns have been raised about potential overfitting of the models. While fears were dispelled as the models consistently performed well on both training and test datasets, it is crucial to implement strategies to ensure the models' generalizability. Particularly, the XG Boost and Random Forest models exhibited remarkable alignment between actual and predicted values, indicating their potential. However, careful consideration is needed to prevent overfitting and ensure reliable predictions.\n",
        "\n",
        "3. **Evaluation Metrics:**\n",
        "   Notably, the R-squared (R2) scores were considerably high, signifying the models' ability to explain the variance in the data. Additionally, the Mean Squared Error (MSE) scores were low, meeting the criteria for a well-performing model. Despite these positive indications, there is a need to delve deeper into the nuances of these metrics and explore other relevant evaluation techniques to ensure the accuracy and reliability of the models.\n",
        "\n",
        "4. **Data Integrity and Feature Engineering:**\n",
        "   It was observed that removing data led to a significant loss of valuable information. Moreover, the introduction of a new column, even if highly correlated with existing features, yielded seemingly favorable results, potentially indicating pseudo-good results. There is a need to explore innovative methods of feature engineering and carefully assess the impact of new features on model performance, ensuring that they genuinely contribute to the predictive power of the models.\n",
        "\n",
        "5. **Model Selection and Tuning:**\n",
        "   The Random Forest model provided the best R2 score, indicating its potential for accurate predictions. However, to prevent overfitting, meticulous tuning of model parameters is necessary. The challenge lies in finding the optimal balance between model complexity and stability, ensuring that the model is robust and reliable in making predictions.\n",
        "\n",
        "Addressing these challenges requires a comprehensive approach, involving advanced outlier detection methods, rigorous evaluation techniques, innovative feature engineering strategies, and meticulous model tuning. By overcoming these challenges, the project aims to build a robust and reliable predictive model for NYC Taxi Trip Time Duration, providing valuable insights for both passengers and service providers in optimizing travel experiences and operational efficiency."
      ],
      "metadata": {
        "id": "2FFDHy2_fqWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  \n",
        "\n",
        "\n",
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n"
      ],
      "metadata": {
        "id": "RWGYrEPufwXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "DWsV49s5gPkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "-nHX6Fz8j_ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "FGbu5KblkMEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd  # For data manipulation and analysis\n",
        "import numpy as np  # For numerical operations\n",
        "import matplotlib.pyplot as plt  # For data visualization\n",
        "import seaborn as sns  # For statistical data visualization\n",
        "from numpy import math  # Import the math module from NumPy\n",
        "from sklearn.preprocessing import StandardScaler  # For standardizing features by removing the mean and scaling to unit variance\n",
        "from sklearn.preprocessing import MinMaxScaler  # For scaling features to a range\n",
        "from sklearn.model_selection import train_test_split  # For splitting the dataset into training and testing sets\n",
        "from sklearn.linear_model import LinearRegression  # For linear regression modeling\n",
        "from sklearn.model_selection import GridSearchCV  # For performing grid search cross-validation\n",
        "from sklearn.tree import DecisionTreeRegressor  # For decision tree regression modeling\n",
        "from sklearn.ensemble import RandomForestRegressor  # For random forest regression modeling\n",
        "from sklearn.metrics import r2_score  # For calculating R-squared score\n",
        "from sklearn.metrics import mean_squared_error  # For calculating mean squared error\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")  # Ignore warnings during code execution\n"
      ],
      "metadata": {
        "id": "FVhfrozZgP7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "XaUxuJf8gP7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code snippet demonstrates the use of the chardet library to detect the character encoding of a given CSV file.\n",
        "file = \"/content/NYC Taxi Data.csv\"\n",
        "import chardet\n",
        "\n",
        "# The file path is specified, and the chardet library is used to analyze the first 100,000 bytes of the file's raw binary data.\n",
        "with open(file, 'rb') as rawdata:\n",
        "    result = chardet.detect(rawdata.read(100000))\n",
        "\n",
        "# The detected character encoding information is then stored in the 'result' variable, which can be used to determine the appropriate encoding for reading the file.\n",
        "result"
      ],
      "metadata": {
        "id": "QlGq1Or3m_wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "# Load Dataset\n",
        "taxi_df = pd.read_csv(file)"
      ],
      "metadata": {
        "id": "nJwtTXBxgP7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "A3Wlsii9gP7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dataset First Look\n",
        "# Dataset head Look\n",
        "taxi_df.head() # Display the first 5 rows of the DataFrame."
      ],
      "metadata": {
        "id": "8-SJEobCgP7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset tail Look\n",
        "taxi_df.tail()  # Display the last 5 rows of the DataFrame."
      ],
      "metadata": {
        "id": "eWjFKMVOnLoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "mB2-XphsgP7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the number of rows in the dataset using the 'shape' attribute\n",
        "print(f'Number of rows in the data set is {taxi_df.shape[0]}')\n",
        "\n",
        "# Display the number of columns in the dataset using the 'shape' attribute\n",
        "print(f'Number of Columns in the data set is {taxi_df.shape[1]}')"
      ],
      "metadata": {
        "id": "qyMkXm0-gP7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "zwLkQZ3DgP7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "taxi_df.info()"
      ],
      "metadata": {
        "id": "X5L_-ku7gP7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "HCGpFYGtgP7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_counts = taxi_df.duplicated(keep=False).sum()\n",
        "\n",
        "# Display the count of duplicate rows\n",
        "print(\"Number of duplicate rows:\", duplicate_counts)"
      ],
      "metadata": {
        "id": "2ZAGrJTrgP7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "mHCdTLfpgP7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "# Count missing values in each column\n",
        "missing_values_count = taxi_df.isnull().sum()\n",
        "print(missing_values_count)"
      ],
      "metadata": {
        "id": "y8oR2qU7gP7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "# Setting the figure size for the visualization\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Creating a heatmap to visualize missing values in the DataFrame\n",
        "sns.heatmap(taxi_df.isnull(), cmap='plasma', annot=False, yticklabels=False)\n",
        "\n",
        "# Adding a title to the visualization\n",
        "plt.title(\"Visualizing Missing Values\")\n",
        "\n",
        "# Displaying the visualization\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_vGt9JZ7gP7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "_a_BAe3LgP7v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here.**\n",
        "#### The data set has 3390 rows 18 columns.\n",
        "#### Data types our data set are: float64(9), int64(6), object(2).\n",
        "#### Zero Duplicate values/rows."
      ],
      "metadata": {
        "id": "f9jWqzeagP7v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "9lzntMOLgP7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "taxi_df.columns"
      ],
      "metadata": {
        "id": "eLOpan-WgP7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "taxi_df.describe(include='all')"
      ],
      "metadata": {
        "id": "qSWH-VSxgP7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "KpaSXw3JgP7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here.**\n",
        "\n",
        "To create a predictive model for NYC taxi trip time, you need a set of variables (features) that can influence the duration of a taxi trip. Here are some potential variables you could consider for your prediction model:\n",
        "\n",
        "1. **Pickup and Dropoff Locations:**\n",
        "   - **Pickup Longitude:** Geographic coordinates of the pickup location.\n",
        "   - **Pickup Latitude** Geographic coordinates of the pickup location.\n",
        "   - **Dropoff Longitude:** Geographic coordinates of the dropoff location.\n",
        "  - **Dropoff Latitude:** Geographic coordinates of the dropoff location.\n",
        "   - **Distance:** The distance between the pickup and dropoff points, either in miles or kilometers.\n",
        "\n",
        "\n",
        "2. **Time and Date:**\n",
        ".\n",
        "   - **Month:** The month in which the trip occurred.\n",
        "   - **pickup_datetime:**  The day when the trip started (in hours and minutes).\n",
        "   - **dropoff_datetime:**  The day when the trip ended (in hours and minutes).\n",
        "\n",
        "3. **Taxi Specifics:**\n",
        "   - **store_and_fwd_flag:** This Flag indicates weather the trip record was held in the vehicle memory before sending it to the vendor because vehicle did not have the connection to the server.Y=store and forward;N=Not a store and forward trip.\n",
        "\n",
        "4. **Additional Features:**\n",
        "   - **passenger_count:** The number of passengers in the taxi.\n",
        "\n",
        "\n",
        "\n",
        "5. **Target Variable:**\n",
        "  - **trip_duration:** Duration/time of trip taken.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "smJTnTTYgP7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "dCNlWKTKgP7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "# Check Unique Values for each variable.\n",
        "# Display unique values for each variable\n",
        "for column in taxi_df.columns:\n",
        "    unique_values = taxi_df[column].nunique()\n",
        "    print(f\"Number of Unique values for {column}:\\n{unique_values}.\")"
      ],
      "metadata": {
        "id": "nV0moQx0gP7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "MjPOd66ZgP7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "JGzLNatogP7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Import the required function from the geopy library for calculating distances between geographic points.\n",
        "from geopy.distance import great_circle\n",
        "\n",
        "# Calculate the distance for each row in the DataFrame and add it as a new column \"Distance\".\n",
        "\n",
        "# Define a lambda function to calculate the great-circle distance between pickup and dropoff points.\n",
        "# The lambda function takes a row from the DataFrame as input and returns the calculated distance.\n",
        "# The `great_circle` function takes two pairs of (latitude, longitude) as input and returns the Distance.\n",
        "taxi_df[\"Distance\"] = taxi_df.apply(lambda row: great_circle((row[\"pickup_latitude\"], row[\"pickup_longitude\"]),(row[\"dropoff_latitude\"], row[\"dropoff_longitude\"])), axis=1)\n"
      ],
      "metadata": {
        "id": "W9Nh-6qngP7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate trip duration in minute\n",
        "taxi_df[\"trip_duration_in_minute\"]=taxi_df[\"trip_duration\"]/60"
      ],
      "metadata": {
        "id": "Nc4h7MT1zoXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting into proper data format\n",
        "# These lines of code are crucial for transforming the original string-based datetime information into a format that can be easily manipulated and analyzed using Pandas and other libraries.\n",
        "taxi_df[\"pickup_datetime\"]=pd.to_datetime(taxi_df[\"pickup_datetime\"])\n",
        "taxi_df[\"dropoff_datetime\"]=pd.to_datetime(taxi_df[\"dropoff_datetime\"])"
      ],
      "metadata": {
        "id": "4z9Z8j9ozoPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finding pickup and drop month\n",
        "# The code is a concise and efficient way to derive month information from datetime values and enhance the DataFrame with additional columns for subsequent analysis.\n",
        "taxi_df[\"pickup_month\"]=taxi_df[\"pickup_datetime\"].dt.month\n",
        "taxi_df[\"dropoff_month\"]=taxi_df[\"dropoff_datetime\"].dt.month"
      ],
      "metadata": {
        "id": "DCnv18gjzwld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating pickup and dropoff day\n",
        "# Extracting day of the month for both pickup and dropoff timestamps\n",
        "taxi_df[\"pickup_day\"] = taxi_df[\"pickup_datetime\"].dt.day  # Extracts the day of the month for pickup\n",
        "taxi_df[\"dropoff_day\"] = taxi_df[\"dropoff_datetime\"].dt.day  # Extracts the day of the month for dropoff\n"
      ],
      "metadata": {
        "id": "5HIhH9hYzwWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding pickup and dropoff weekday\n",
        "# This code is enhancing the taxi_df DataFrame by including the day of the week on which each taxi ride was picked up and dropped off.\n",
        "taxi_df[\"pickup_weekday\"]=taxi_df[\"pickup_datetime\"].dt.weekday\n",
        "taxi_df[\"dropoff_weekday\"]=taxi_df[\"dropoff_datetime\"].dt.weekday"
      ],
      "metadata": {
        "id": "jzJqvsprzwTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating pickup and dropoff hours\n",
        "# Extracting the hour component from the pickup_datetime and dropoff_datetime columns\n",
        "taxi_df[\"pickup_hour\"] = taxi_df[\"pickup_datetime\"].dt.hour\n",
        "taxi_df[\"dropoff_hour\"] = taxi_df[\"dropoff_datetime\"].dt.hour"
      ],
      "metadata": {
        "id": "wKha1Z-1zwNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a function to check null values and unique values\n",
        "def information() : # This line defines a function named information.\n",
        "    x = pd.DataFrame(index=taxi_df.columns)  # Within the function, a new DataFrame named x is created.\n",
        "    x[\"data type\"] = taxi_df.dtypes\n",
        "    x[\"null values\"] = taxi_df.isnull().sum()\n",
        "    x[\"unique\"] = taxi_df.nunique()\n",
        "    return x"
      ],
      "metadata": {
        "id": "F_1_fcjlzwHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'store_and_fwd_flag' column values from categorical to numerical\n",
        "# Replace 'Y' with 1 and 'N' with 0\n",
        "taxi_df['store_and_fwd_flag'] = taxi_df['store_and_fwd_flag'].replace({'Y': 1, 'N': 0})"
      ],
      "metadata": {
        "id": "giJ-M84upwo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'distance' column to float\n",
        "taxi_df['Distance'] = taxi_df['Distance'].apply(lambda x: float(x.miles))"
      ],
      "metadata": {
        "id": "ezEwgRe-zwDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This line of Python code is modifying a DataFrame named taxi_df.\n",
        "taxi_df[\"pickup_month\"] = taxi_df['pickup_month'].astype(float)\n",
        "taxi_df[\"pickup_day\"] = taxi_df[\"pickup_day\"].astype(float)"
      ],
      "metadata": {
        "id": "q6K8Zgcwzv-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#taxi_df = pd.DataFrame(taxi_df)\n",
        "\n",
        "# Convert \"pickup_day\" column to float (just an example, may not be relevant to your data)\n",
        "try:\n",
        "    taxi_df[\"pickup_day\"] = taxi_df[\"pickup_day\"].astype(float)\n",
        "except ValueError as e:\n",
        "    print(\"Error:\", e)\n",
        "    print(\"Conversion to float failed.\")"
      ],
      "metadata": {
        "id": "tu82ODm7zoK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "c9GPu29igP7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "vYyAnJyqgP7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "hH23-qtre5h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chart 1**"
      ],
      "metadata": {
        "id": "EqMD0mLNSTQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The distribution of Number of Pickups and Dropoffs on each part of the day.\n",
        "\n"
      ],
      "metadata": {
        "id": "szSmj4YJ1NfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "\n",
        "# Diving the time into different timezone.\n",
        "def determine_time_of_day(hour_input):\n",
        "    # Check if the input hour falls within the morning period (6 AM to 10 AM).\n",
        "    if hour_input >= 6 and hour_input <= 10:\n",
        "        return \"Morning\"\n",
        "    # Check if the input hour falls within the mid-day period (10 AM to 4 PM).\n",
        "    elif hour_input >= 10 and hour_input <= 16:\n",
        "        return \"Midday\"\n",
        "    # Check if the input hour falls within the evening period (4 PM to 10 PM).\n",
        "    elif hour_input >= 16 and hour_input <= 22:\n",
        "        return \"Evening\"\n",
        "    # Check if the input hour falls within the late night period (10 PM to 6 AM).\n",
        "    elif hour_input >= 22 or hour_input <= 6:\n",
        "        return \"Late Night\"\n",
        "\n",
        "# Example usage:\n",
        "hour = 14  # Replace this with the hour you want to determine the time of day for.\n",
        "time_of_day = determine_time_of_day(hour)\n",
        "print(f\"The input hour {hour} corresponds to: {time_of_day}\")\n"
      ],
      "metadata": {
        "id": "IGcKWs4s4_Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply that function\n",
        "# Apply the determine_time_of_day function to create new columns for pickup and dropoff time zones.\n",
        "taxi_df[\"pickup_time_of_day\"] = taxi_df.pickup_hour.apply(determine_time_of_day)\n",
        "taxi_df[\"dropoff_time_of_day\"] = taxi_df.dropoff_hour.apply(determine_time_of_day)"
      ],
      "metadata": {
        "id": "AKs0ZGefWRKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of the no of pickups and Dropoffs in a day\n",
        "\n",
        "# Create a figure with two subplots side by side\n",
        "figure, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "# Create a count plot for the distribution of pickup time zones\n",
        "pickup_plot = sns.countplot(x='pickup_time_of_day', data=taxi_df, ax=ax[0])\n",
        "ax[0].set_title('Number of Pickups During Different Parts of the Day')\n",
        "ax[0].set_xlabel('Time of Day')\n",
        "ax[0].set_ylabel('Number of Pickups')\n",
        "\n",
        "# Annotate bars with their counts for pickup plot\n",
        "for p in pickup_plot.patches:\n",
        "    pickup_plot.annotate(format(p.get_height(), '.0f'),\n",
        "                         (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                         ha='center', va='center',\n",
        "                         xytext=(0, 9),\n",
        "                         textcoords='offset points')\n",
        "\n",
        "# Create a count plot for the distribution of dropoff time zones\n",
        "dropoff_plot = sns.countplot(x='dropoff_time_of_day', data=taxi_df, ax=ax[1])\n",
        "ax[1].set_title('Number of Dropoffs During Different Parts of the Day')\n",
        "ax[1].set_xlabel('Time of Day')\n",
        "ax[1].set_ylabel('Number of Dropoffs')\n",
        "\n",
        "# Annotate bars with their counts for dropoff plot\n",
        "for p in dropoff_plot.patches:\n",
        "    dropoff_plot.annotate(format(p.get_height(), '.0f'),\n",
        "                          (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                          ha='center', va='center',\n",
        "                          xytext=(0, 9),\n",
        "                          textcoords='offset points')\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fOeEK3y8jlrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Why did you pick the specific chart?**\n"
      ],
      "metadata": {
        "id": "Dk_X33iP_xT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with two subplots side by side\n",
        "figure, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "# Create a count plot for the distribution of pickup time zones\n",
        "pickup_plot = sns.countplot(x='pickup_time_of_day', data=taxi_df, ax=ax[0])\n",
        "ax[0].set_title('Number of Pickups During Different Parts of the Day')\n",
        "ax[0].set_xlabel('Time of Day')\n",
        "ax[0].set_ylabel('Number of Pickups')\n",
        "\n",
        "# Annotate bars with their counts for pickup plot\n",
        "for p in pickup_plot.patches:\n",
        "    pickup_plot.annotate(format(p.get_height(), '.0f'),\n",
        "                         (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                         ha='center', va='center',\n",
        "                         xytext=(0, 9),\n",
        "                         textcoords='offset points')\n",
        "\n",
        "# Create a count plot for the distribution of dropoff time zones\n",
        "dropoff_plot = sns.countplot(x='dropoff_time_of_day', data=taxi_df, ax=ax[1])\n",
        "ax[1].set_title('Number of Dropoffs During Different Parts of the Day')\n",
        "ax[1].set_xlabel('Time of Day')\n",
        "ax[1].set_ylabel('Number of Dropoffs')\n",
        "\n",
        "# Annotate bars with their counts for dropoff plot\n",
        "for p in dropoff_plot.patches:\n",
        "    dropoff_plot.annotate(format(p.get_height(), '.0f'),\n",
        "                          (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                          ha='center', va='center',\n",
        "                          xytext=(0, 9),\n",
        "                          textcoords='offset points')\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gzEi7pLfWR03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Answer Here.**\n",
        "\n",
        "The specific charts used in this code are count plots (bar charts) showing the distribution of taxi pickups and dropoffs across different parts of the day. The code divides the time into four categories: morning, mid day, evening, and late night, and then visualizes the number of pickups and dropoffs in each of these time zones.\n",
        "\n",
        "Understanding Time-based Patterns: The objective of the visualization is to understand the distribution of taxi pickups and dropoffs across different parts of the day. Count plots are suitable for displaying the frequency or count of categorical data, making them ideal for visualizing the number of pickups and dropoffs in each time zone."
      ],
      "metadata": {
        "id": "a5h4NlHScIDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **2. What is/are the insight(s) found from the chart?**"
      ],
      "metadata": {
        "id": "ahLesGy8cHys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with two subplots side by side\n",
        "figure, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "# Create a count plot for the distribution of pickup time zones\n",
        "pickup_plot = sns.countplot(x='pickup_time_of_day', data=taxi_df, ax=ax[0])\n",
        "ax[0].set_title('Number of Pickups During Different Parts of the Day')\n",
        "ax[0].set_xlabel('Time of Day')\n",
        "ax[0].set_ylabel('Number of Pickups')\n",
        "\n",
        "# Annotate bars with their counts for pickup plot\n",
        "for p in pickup_plot.patches:\n",
        "    pickup_plot.annotate(format(p.get_height(), '.0f'),\n",
        "                         (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                         ha='center', va='center',\n",
        "                         xytext=(0, 9),\n",
        "                         textcoords='offset points')\n",
        "\n",
        "# Create a count plot for the distribution of dropoff time zones\n",
        "dropoff_plot = sns.countplot(x='dropoff_time_of_day', data=taxi_df, ax=ax[1])\n",
        "ax[1].set_title('Number of Dropoffs During Different Parts of the Day')\n",
        "ax[1].set_xlabel('Time of Day')\n",
        "ax[1].set_ylabel('Number of Dropoffs')\n",
        "\n",
        "# Annotate bars with their counts for dropoff plot\n",
        "for p in dropoff_plot.patches:\n",
        "    dropoff_plot.annotate(format(p.get_height(), '.0f'),\n",
        "                          (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                          ha='center', va='center',\n",
        "                          xytext=(0, 9),\n",
        "                          textcoords='offset points')\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MgTCxCv5rNK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "**Insights from the Charts:**\n",
        "\n",
        "**Pickup Distribution:**\n",
        "\n",
        "The first chart shows the number of pickups during different parts of the day.\n",
        "Most pickups occur during the evening period (4 PM to 10 PM), indicating high demand for taxis in the evening hours.\n",
        "Pickup counts are relatively lower in the morning (6 AM to 10 AM) and mid day (10 AM to 4 PM) periods.\n",
        "There is a moderate demand for taxis in the late night period (10 PM to 6 AM).\n",
        "\n",
        "\n",
        "**Dropoff Distribution:**\n",
        "\n",
        "The second chart represents the number of dropoffs during different times of the day.\n",
        "Similar to pickups, the majority of dropoffs happen in the evening period, suggesting that people tend to travel more during the evening hours and need taxis to reach their destinations.\n",
        "Dropoff counts are lower during the morning and mid day periods.\n",
        "The late night period also shows a moderate number of dropoffs, indicating that taxi services are still in demand during these hours, albeit less than the evening."
      ],
      "metadata": {
        "id": "wyzhTueocHms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason.**"
      ],
      "metadata": {
        "id": "MeCj7bVJcHZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "The NYC Taxi Trip Time Prediction dataset by categorizing pickup and dropoff times into different time zones (morning, midday, evening, late night) and visualizes the distribution of pickups and dropoffs in each part of the day.\n",
        "\n",
        "**Positive Business Impact:**\n",
        "**Operational Efficiency:** Understanding peak pickup and dropoff times can help taxi companies allocate their resources more efficiently. They can deploy more drivers during high-demand periods, reducing customer wait times and increasing overall customer satisfaction.\n",
        "\n",
        "**Optimized Pricing Strategies:** By recognizing high-demand periods, taxi companies can implement dynamic pricing models. Higher prices during peak times can increase revenue, while lower prices during off-peak hours can attract more customers.\n",
        "\n",
        "**Insights Leading to Negative Growth:**\n",
        "\n",
        "**Overcrowding during Peak Hours:** If the analysis reveals consistent overcrowding during peak hours, it could lead to negative customer experiences. Passengers might find it difficult to get a taxi, leading to frustration and potential loss of customers.\n",
        "\n",
        "**Increased Operational Costs:** If demand peaks are too high and consistent, taxi companies might need to invest in expanding their fleet. While this can cater to high demand, it also leads to increased operational costs, which need to be balanced with the increased revenue."
      ],
      "metadata": {
        "id": "UFZy5SPAcHJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   We can see that evening is the busiet time of whole day. people take the taxi to come from office and going for party at evening and dinner. after that at mid day maximum ride taken because people were going to office after 10:00 AM.\n",
        "\n"
      ],
      "metadata": {
        "id": "dsIIw_Hud9YK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chart-2"
      ],
      "metadata": {
        "id": "qjzJe6dyYk-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A line plot for the relationship between 'pickup_month' and 'trip_duration'.\n",
        "\n"
      ],
      "metadata": {
        "id": "QtD-_m8c1Ui7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "taxi_df[\"pickup_month\"] = taxi_df['pickup_month'].astype(float)"
      ],
      "metadata": {
        "id": "XxZD4cDySh1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the style and context for the plot\n",
        "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
        "\n",
        "# Creating a line plot for the relationship between 'pickup_month' and 'trip_duration'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='pickup_month', y='trip_duration', data=taxi_df, color='green', linewidth=2, marker='o')\n",
        "\n",
        "# Adding labels and title to the plot\n",
        "plt.xlabel('Month', fontsize=14, labelpad=12)\n",
        "plt.ylabel('Trip Duration (seconds)', fontsize=14, labelpad=12)\n",
        "plt.title('Trip Duration Variation Over Months', fontsize=16, pad=20)\n",
        "\n",
        "# Customize x-axis ticks (if needed)\n",
        "# plt.xticks(ticks=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Og-6P5NAvIw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Why did you pick the specific chart?**\n",
        "\n"
      ],
      "metadata": {
        "id": "GNf-HouA_-R6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the style and context for the plot\n",
        "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
        "\n",
        "# Creating a line plot for the relationship between 'pickup_month' and 'trip_duration'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='pickup_month', y='trip_duration', data=taxi_df, color='green', linewidth=2, marker='o')\n",
        "\n",
        "# Adding labels and title to the plot\n",
        "plt.xlabel('Month', fontsize=14, labelpad=12)\n",
        "plt.ylabel('Trip Duration (seconds)', fontsize=14, labelpad=12)\n",
        "plt.title('Trip Duration Variation Over Months', fontsize=16, pad=20)\n",
        "\n",
        "# Customize x-axis ticks (if needed)\n",
        "# plt.xticks(ticks=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QAQ9aotirT3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "The chosen chart in the provided code is a line plot representing the relationship between the 'pickup_month' (x-axis) and 'trip_duration' (y-axis) for the NYC Taxi Trip time Prediction dataset.\n",
        "\n",
        "**The line plot is suitable for this scenario for several reasons:**\n",
        "\n",
        "**Time Series Data Representation:** Line plots are ideal for visualizing data points over a continuous interval or time series. In this case, the x-axis represents months, which is a continuous variable, making it suitable for a line plot.\n",
        "\n",
        "**Sequential Data:** Line plots are used to display data points in sequence and to show trends over a period of time. In this plot, months are sequential and have a specific order, making it meaningful to connect them with lines to observe the trend in trip durations over the months."
      ],
      "metadata": {
        "id": "9-yY30lBciPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **2. What is/are the insight(s) found from the chart?**\n",
        "\n"
      ],
      "metadata": {
        "id": "SH1GCMwhciCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the style and context for the plot\n",
        "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
        "\n",
        "# Creating a line plot for the relationship between 'pickup_month' and 'trip_duration'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='pickup_month', y='trip_duration', data=taxi_df, color='green', linewidth=2, marker='o')\n",
        "\n",
        "# Adding labels and title to the plot\n",
        "plt.xlabel('Month', fontsize=14, labelpad=12)\n",
        "plt.ylabel('Trip Duration (seconds)', fontsize=14, labelpad=12)\n",
        "plt.title('Trip Duration Variation Over Months', fontsize=16, pad=20)\n",
        "\n",
        "# Customize x-axis ticks (if needed)\n",
        "# plt.xticks(ticks=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wl5exDRhrWJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "\n",
        "It seems that you are visualizing the relationship between the pickup month and the trip duration for the NYC Taxi Trip Time Prediction dataset. Here are the insights that can be derived from the chart:\n",
        "\n",
        "**Seasonal Patterns:** If the x-axis represents the months of the year, the chart can provide insights into the seasonal patterns of taxi trip durations. For instance, there might be longer trip durations during certain months, possibly indicating a busy tourist season or weather-related factors.\n",
        "\n",
        "**Monthly Variations:** The chart can reveal any variations in trip durations from month to month. For example, there might be a consistent increase or decrease in trip durations over several months, suggesting a trend."
      ],
      "metadata": {
        "id": "UY5ZN0Cwch2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason.**"
      ],
      "metadata": {
        "id": "yUBiKB98chqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "\n",
        "**Positive Business Impact:**\n",
        "The line plot visualizes how trip duration varies across different months of the year. Positive insights that can lead to a business impact include identifying patterns or trends in trip durations. For example:\n",
        "\n",
        "**Seasonal Demand Understanding:** If the plot shows a clear pattern where trip durations increase during specific months (such as summer vacation or holiday seasons), the taxi service can anticipate increased demand during these periods. This insight can help in optimizing the fleet and staffing levels to efficiently handle the higher demand, leading to better customer satisfaction and potentially increased revenue.\n",
        "\n",
        "**Promotion and Pricing Strategies:** If there are months with consistently shorter trip durations, taxi companies can introduce promotional offers or discounts during these periods to attract more customers. Additionally, understanding the variations can help in dynamic pricing strategies, ensuring that prices align with demand, maximizing profitability during peak times, and encouraging ridership during off-peak periods.\n",
        "\n",
        "\n",
        "**Negative Business Impact:**\n",
        "Without specific details about the dataset and the actual plot generated, it's challenging to identify negative trends definitively. However, potential negative insights could include:\n",
        "\n",
        "**Unpredictable Spikes in Trip Duration:** If there are random and unpredictable spikes in trip durations across various months, it might indicate issues such as traffic congestion, road closures, or other factors causing delays. In this case, taxi services might face challenges in providing reliable and timely transportation, leading to customer dissatisfaction and potential loss of business.\n",
        "\n",
        "**Consistently Long Trip Durations:** If the plot consistently shows long trip durations across all months, it might suggest inefficiencies in routes, traffic management, or service optimization. Prolonged trip durations could discourage customers from using the service, leading to decreased ridership and revenue.\n",
        "\n"
      ],
      "metadata": {
        "id": "i2Ekxt9CchbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   From February, we can see trip duration rising every month.\n",
        "\n"
      ],
      "metadata": {
        "id": "IDLe0mz7iPSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chart-3"
      ],
      "metadata": {
        "id": "L6OPFhJjW5-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distribution of number of Pickups During 24 Hours.\n",
        "\n"
      ],
      "metadata": {
        "id": "naX-6_Ab1bsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "\n",
        "# Create a 1x2 grid of subplots with a combined figure size of 15x5 inches\n",
        "figure, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "# Create a countplot for the \"pickup_day\" column on the left subplot (ax[0])\n",
        "pickup_plot = sns.countplot(x=\"pickup_day\", data=taxi_df, ax=ax[0])\n",
        "\n",
        "# Set a title for the left subplot\n",
        "ax[0].set_title('No. of pickups done on each day')\n",
        "\n",
        "# Annotate each bar with its count for the left subplot\n",
        "for p in pickup_plot.patches:\n",
        "    pickup_plot.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                         ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n",
        "                         textcoords='offset points')\n",
        "\n",
        "# Create a countplot for the \"dropoff_day\" column on the right subplot (ax[1])\n",
        "dropoff_plot = sns.countplot(x='dropoff_day', data=taxi_df, ax=ax[1])\n",
        "\n",
        "# Set a title for the right subplot\n",
        "ax[1].set_title('No. of dropoff done on each day')\n",
        "\n",
        "# Annotate each bar with its count for the right subplot\n",
        "for p in dropoff_plot.patches:\n",
        "    dropoff_plot.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                          ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n",
        "                          textcoords='offset points')\n",
        "\n",
        "# Display the complete figure with both subplots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "55evE9gAQOyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Why did you pick the specific chart?**"
      ],
      "metadata": {
        "id": "-tF37XbJAAHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 1x2 grid of subplots with a combined figure size of 15x5 inches\n",
        "figure, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "# Create a countplot for the \"pickup_day\" column on the left subplot (ax[0])\n",
        "pickup_plot = sns.countplot(x=\"pickup_day\", data=taxi_df, ax=ax[0])\n",
        "\n",
        "# Set a title for the left subplot\n",
        "ax[0].set_title('No. of pickups done on each day')\n",
        "\n",
        "# Annotate each bar with its count for the left subplot\n",
        "for p in pickup_plot.patches:\n",
        "    pickup_plot.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                         ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n",
        "                         textcoords='offset points')\n",
        "\n",
        "# Create a countplot for the \"dropoff_day\" column on the right subplot (ax[1])\n",
        "dropoff_plot = sns.countplot(x='dropoff_day', data=taxi_df, ax=ax[1])\n",
        "\n",
        "# Set a title for the right subplot\n",
        "ax[1].set_title('No. of dropoff done on each day')\n",
        "\n",
        "# Annotate each bar with its count for the right subplot\n",
        "for p in dropoff_plot.patches:\n",
        "    dropoff_plot.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                          ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n",
        "                          textcoords='offset points')\n",
        "\n",
        "# Display the complete figure with both subplots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jg5uMnU4wYi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "A countplot is a type of categorical plot provided by the seaborn library. It shows the counts of observations in each categorical bin using bars. In this case, the countplot is used to visualize the distribution of taxi pickups and dropoffs across different days of the week.\n",
        "\n",
        "**Here's why the countplot was chosen for this scenario:**\n",
        "\n",
        "**Categorical Data Representation:** The variables being plotted, i.e., \"pickup_day\" and \"dropoff_day,\" are categorical in nature. Countplots are ideal for visualizing the distribution of categorical variables. Each bar in the countplot represents the count of occurrences of a specific category.\n",
        "\n",
        "**Comparison between Categories:** The countplot allows for a clear visual comparison between the number of pickups and dropoffs on different days of the week. By placing the plots side by side, it's easy to compare the patterns between the two categories."
      ],
      "metadata": {
        "id": "3lTZ-R6Tc0Os"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **2. What is/are the insight(s) found from the chart?**\n"
      ],
      "metadata": {
        "id": "cBXh73vtc0CE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "The provided code creates a side-by-side comparison of the number of pickups and dropoffs made on each day of the week using the NYC Taxi Trip Time Prediction dataset. Here are the insights that can be derived from the chart:\n",
        "\n",
        "**Peak Pickup and Dropoff Days:**\n",
        "By observing the left subplot (No. of pickups done on each day) and the right subplot (No. of dropoffs done on each day), you can identify the days with the highest number of taxi pickups and dropoffs. These days are likely to be the busiest for taxi services. For example, if Wednesday has the highest bars in both plots, it suggests that Wednesdays are the peak days for taxi activities.\n",
        "\n",
        "**Comparison of Pickup and Dropoff Patterns:**\n",
        "By comparing the heights of the bars in the left and right subplots for each day, you can gain insights into the balance between pickups and dropoffs on different days. For instance, if the pickups are significantly higher than dropoffs on weekends (Saturday and Sunday), it could indicate that people are using taxis to go out and socialize but not necessarily returning with taxis. On the other hand, if the dropoffs are higher than pickups on weekdays, it might mean people are using taxis to commute to work or other destinations and returning home with alternative transportation."
      ],
      "metadata": {
        "id": "MXHWiX5aczfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason.**"
      ],
      "metadata": {
        "id": "3ZAUbVdZczSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "\n",
        "**Positive Business Impact:**\n",
        "\n",
        "**Peak Hours and Days:** The visualization can help identify peak hours and days with high demand for taxi services. This information can be used to allocate more resources (taxis and drivers) during these times, ensuring efficient service and higher customer satisfaction.\n",
        "\n",
        "**Demand Patterns:** Recognizing patterns in pickup and dropoff days can allow the business to predict future demand accurately. This predictive ability helps in optimizing taxi dispatching and ensures that taxis are available where and when they are needed the most.\n",
        "\n",
        "**Customer Behavior Analysis:** By understanding which days have the highest demand, the business can analyze the reasons behind these patterns. For example, if Fridays and Saturdays have significantly more pickups and dropoffs, it might indicate a high demand for nightlife transportation. This insight could lead to targeted marketing or special offers during these times to attract more customers.\n",
        "\n",
        "\n",
        "**Negative Growth:**\n",
        "\n",
        "**Inefficient Resource Allocation:** If the business does not analyze these patterns and fails to allocate resources efficiently, there could be periods of unmet demand (not enough taxis during peak times) or excess supply (too many taxis during low-demand times). This inefficiency can lead to increased operational costs and decreased customer satisfaction.\n",
        "\n",
        "**Missed Revenue Opportunities:** Without understanding demand patterns, the business might miss opportunities to increase prices during high-demand periods (such as holidays or events). Failing to capitalize on these opportunities can result in missed revenue potential.\n",
        "\n",
        "**Poor Customer Experience:** Inconsistencies in service availability can lead to poor customer experiences. If customers frequently find it difficult to get a taxi during peak hours, they might switch to alternative transportation options, leading to customer loss and negative growth."
      ],
      "metadata": {
        "id": "YAfZiadmczFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chart-4"
      ],
      "metadata": {
        "id": "y2kZ5GakiZNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grouping the data in the 'taxi_df' DataFrame by \"pickup_month\" and \"vendor_id\".\n",
        "\n"
      ],
      "metadata": {
        "id": "pJA_TDrn1juQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "\n",
        "# Aggregate vendor id by pickup month\n",
        "# Grouping the data in the 'taxi_df' DataFrame by \"pickup_month\" and \"vendor_id\"\n",
        "monthly_pickup_by_vendor = taxi_df.groupby([\"pickup_month\", \"vendor_id\"]).size()\n",
        "\n",
        "# Unstacking the grouped data to create a pivot table-like structure\n",
        "monthly_pickup_by_vendor = monthly_pickup_by_vendor.unstack()\n",
        "\n",
        "# Set the size of the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plotting the data as a line chart\n",
        "monthly_pickup_by_vendor.plot(kind='line', linewidth=2, marker='o', markersize=8, color=['blue', 'green'])\n",
        "\n",
        "# Adding a title\n",
        "plt.title('Monthly Pickup Count by Vendor', fontsize=16)\n",
        "\n",
        "# Adding labels to the x and y axes\n",
        "plt.xlabel('Months', fontsize=14)\n",
        "plt.ylabel('Number of Trips', fontsize=14)\n",
        "\n",
        "# Adding a legend to distinguish between vendors\n",
        "plt.legend(['Vendor 1', 'Vendor 2'], fontsize=12)\n",
        "\n",
        "# Adding grid lines for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Adding annotations for specific data points (optional)\n",
        "# plt.annotate('Peak Month', xy=(peak_month, peak_value), xytext=(peak_month-2, peak_value+5000),\n",
        "#              arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6kG2sGfdWQ4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Why did you pick the specific chart?**"
      ],
      "metadata": {
        "id": "TIfxJHxWAFdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the size of the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plotting the data as a line chart\n",
        "monthly_pickup_by_vendor.plot(kind='line', linewidth=2, marker='o', markersize=8, color=['blue', 'green'])\n",
        "\n",
        "# Adding a title\n",
        "plt.title('Monthly Pickup Count by Vendor', fontsize=16)\n",
        "\n",
        "# Adding labels to the x and y axes\n",
        "plt.xlabel('Months', fontsize=14)\n",
        "plt.ylabel('Number of Trips', fontsize=14)\n",
        "\n",
        "# Adding a legend to distinguish between vendors\n",
        "plt.legend(['Vendor 1', 'Vendor 2'], fontsize=12)\n",
        "\n",
        "# Adding grid lines for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Adding annotations for specific data points (optional)\n",
        "# plt.annotate('Peak Month', xy=(peak_month, peak_value), xytext=(peak_month-2, peak_value+5000),\n",
        "#              arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XzAaXXWNIsjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "\n",
        "**Temporal Data Representation:** Line charts are particularly useful for displaying data points in a continuous manner, making them ideal for showing trends over time. In this case, the data is being analyzed on a monthly basis, so a line chart is appropriate for displaying how the number of trips varies over the months.\n",
        "\n",
        "**Comparison between Categories:** The line chart allows for a clear comparison between the two vendors (Vendor 1 and Vendor 2) over the months. Each vendor is represented by a different colored line, making it easy for viewers to distinguish between them."
      ],
      "metadata": {
        "id": "cY0EyOD4dMKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **2. What is/are the insight(s) found from the chart?**\n"
      ],
      "metadata": {
        "id": "Wq3ScWngdIeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the size of the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plotting the data as a line chart\n",
        "monthly_pickup_by_vendor.plot(kind='line', linewidth=2, marker='o', markersize=8, color=['blue', 'green'])\n",
        "\n",
        "# Adding a title\n",
        "plt.title('Monthly Pickup Count by Vendor', fontsize=16)\n",
        "\n",
        "# Adding labels to the x and y axes\n",
        "plt.xlabel('Months', fontsize=14)\n",
        "plt.ylabel('Number of Trips', fontsize=14)\n",
        "\n",
        "# Adding a legend to distinguish between vendors\n",
        "plt.legend(['Vendor 1', 'Vendor 2'], fontsize=12)\n",
        "\n",
        "# Adding grid lines for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Adding annotations for specific data points (optional)\n",
        "# plt.annotate('Peak Month', xy=(peak_month, peak_value), xytext=(peak_month-2, peak_value+5000),\n",
        "#              arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2JU9M_7DIu27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "**Vendor Comparison:** The chart allows for a visual comparison between Vendor 1 and Vendor 2 in terms of their monthly pickup counts. By observing the relative heights of the lines, you can quickly identify which vendor consistently handles more pickups throughout the months.\n",
        "\n",
        "**Seasonal Patterns:** If there are recurring peaks or troughs in the lines for both vendors, it indicates a seasonal pattern in the number of pickups. For instance, if there is a significant increase in pickups during summer months or holiday seasons, these patterns would be visible on the chart.\n",
        "\n",
        "**Anomalies or Outliers:** Sudden spikes or drops in the number of pickups can signify anomalies or special events. For example, if there is an unusually high number of pickups in a specific month, it might indicate a local event, festival, or occurrence that led to increased demand for taxis."
      ],
      "metadata": {
        "id": "R4uLlHDJdJDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason**"
      ],
      "metadata": {
        "id": "LJswWz2idKla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "The NYC Taxi Trip Time Prediction dataset by grouping the data based on pickup month and vendor ID, then visualizing the monthly pickup counts for two specific vendors (Vendor 1 and Vendor 2) using a line chart.\n",
        "\n",
        "\n",
        "**Positive Business Impact:**\n",
        "\n",
        "\n",
        "**Identifying Peak Months:** Understanding which months have the highest demand for taxi services (peak months) can be invaluable for taxi companies. They can allocate more resources (taxis and drivers) during these periods to meet the high demand, thereby improving customer satisfaction and potentially increasing revenue.\n",
        "\n",
        "**Optimizing Vendor Performance:** By comparing the performance of different vendors, taxi companies can identify which vendor is performing better in terms of the number of trips. Positive insights, such as one vendor consistently outperforming the other, can lead to strategic decisions. For example, collaborating more with the efficient vendor or learning from their strategies to improve the overall service quality.\n",
        "\n",
        "**Strategic Decision Making:** Insights derived from this analysis can help in making data-driven decisions. For instance, taxi companies can adjust their marketing strategies or promotional offers during specific months to attract more customers. They can also plan maintenance schedules and driver shifts more effectively based on anticipated demand fluctuations.\n",
        "\n",
        "**Potential Negative Impact:**\n",
        "\n",
        "**Overlooking Other Factors:** While the number of trips is important, focusing solely on this metric might lead to overlooking other crucial factors affecting business performance, such as customer satisfaction, trip duration, and profitability. Ignoring these factors could result in a negative impact in the long run, as customer experience is a key driver for the taxi service industry.\n",
        "\n",
        "**Incomplete Insights:** Analyzing only the number of trips by vendors might not provide a comprehensive understanding of customer behavior and preferences. To create a positive impact, it's essential to complement this analysis with other data sources (like customer feedback, weather data, or events happening in the city) to gain a holistic view of the business landscape."
      ],
      "metadata": {
        "id": "XBalGCs5dJ1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  We can see that both vendors trips are maximum at month of March and lowest at the month of January, February and after June.\n",
        "\n"
      ],
      "metadata": {
        "id": "7ufN37yxXdsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chart-5"
      ],
      "metadata": {
        "id": "pJg50NYpgQQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a count plot using seaborn, using the \"passenger_count\" column from the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "X9OomOo71qsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "\n",
        "# Passenger count\n",
        "taxi_df.passenger_count.value_counts()"
      ],
      "metadata": {
        "id": "gL2BG5bfVF3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size for the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a count plot using seaborn, using the \"passenger_count\" column from the dataset\n",
        "sns.countplot(x=taxi_df[\"passenger_count\"], palette=\"viridis\")  # You can change the palette to your preference\n",
        "\n",
        "# Set labels for x and y axes\n",
        "plt.xlabel('Number of Passengers', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "\n",
        "# Set the title for the plot\n",
        "plt.title('Distribution of Passenger Count', fontsize=16)\n",
        "\n",
        "# Rotate x-axis labels for better visibility\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hl1BAZ9IqEaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Why did you pick the specific chart?**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tpLXKYjhAIwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size for the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a count plot using seaborn, using the \"passenger_count\" column from the dataset\n",
        "sns.countplot(x=taxi_df[\"passenger_count\"], palette=\"viridis\")  # You can change the palette to your preference\n",
        "\n",
        "# Set labels for x and y axes\n",
        "plt.xlabel('Number of Passengers', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "\n",
        "# Set the title for the plot\n",
        "plt.title('Distribution of Passenger Count', fontsize=16)\n",
        "\n",
        "# Rotate x-axis labels for better visibility\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7VhrpQzqvmHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "A count plot is a type of categorical plot that shows the counts of observations in each category using bars. In this case, it displays the distribution of passenger counts in the NYC Taxi Trip Time Prediction dataset.\n",
        "\n",
        "The choice of this chart is suitable for visualizing the distribution of discrete categorical data, which is the passenger count in this scenario. Here's why this specific chart was picked:\n",
        "\n",
        "Categorical Data Representation: The \"passenger_count\" column contains discrete categorical data, representing the number of passengers in each taxi trip. Count plots are ideal for visualizing the distribution of such data by displaying the frequency of each category.\n",
        "\n",
        "Clarity and Simplicity: Count plots are simple and easy to interpret. They provide a clear visual representation of the distribution without the complexities of other types of plots, making it accessible for a wide range of audiences."
      ],
      "metadata": {
        "id": "THGpvsa6dj-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **2. What is/are the insight(s) found from the chart?**"
      ],
      "metadata": {
        "id": "k6HTy1j7djy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size for the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a count plot using seaborn, using the \"passenger_count\" column from the dataset\n",
        "sns.countplot(x=taxi_df[\"passenger_count\"], palette=\"viridis\")  # You can change the palette to your preference\n",
        "\n",
        "# Set labels for x and y axes\n",
        "plt.xlabel('Number of Passengers', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "\n",
        "# Set the title for the plot\n",
        "plt.title('Distribution of Passenger Count', fontsize=16)\n",
        "\n",
        "# Rotate x-axis labels for better visibility\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TeGtjxGFvoDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "The provided code creates a count plot showing the distribution of passenger counts in the NYC Taxi Trip Time Prediction dataset. The x-axis represents the number of passengers, and the y-axis represents the count of trips for each passenger count. The insights that can be gathered from this chart include:\n",
        "\n",
        "Most trips have a single passenger: The chart likely shows a peak at the passenger count of 1, indicating that a significant portion of the taxi trips in the dataset involve solo passengers. This is a common scenario in taxi services where individuals travel alone.\n",
        "\n",
        "Decreasing frequency with more passengers: As the passenger count increases, the number of trips tends to decrease. This is expected because fewer trips involve multiple passengers. This insight is valuable for understanding the typical passenger group size in the dataset."
      ],
      "metadata": {
        "id": "qOsL0c6ndjfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason.**"
      ],
      "metadata": {
        "id": "CVuDrDpodjUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "Analyzing passenger count distribution can provide valuable insights that might help businesses optimize their services. Here's how the insights gained from this plot could potentially impact a taxi service business:\n",
        "\n",
        "**Positive Business Impact:**\n",
        "\n",
        "**Optimizing Fleet Size:** By understanding the distribution of passenger counts, taxi companies can optimize their fleet size. For instance, if a significant portion of the rides consists of single passengers, the company might consider having more compact cars in their fleet, which are more fuel-efficient and cost-effective.\n",
        "\n",
        "**Targeted Marketing:** Knowing the common passenger counts allows for targeted marketing efforts. For example, if a large number of trips involve groups of 4 or more passengers, the company could create special offers or discounts for group rides, thereby attracting more customers and increasing revenue.\n",
        "\n",
        "**Service Customization:** Companies can customize their services based on passenger count patterns. For instance, if there are many solo travelers during specific times, the company could introduce single-passenger ride packages at discounted rates during those hours, attracting more solo riders.\n",
        "\n",
        "**Potential Negative Impact (if not analyzed and addressed):**\n",
        "\n",
        "**Inefficient Resource Allocation:** If a taxi company does not pay attention to the distribution of passenger counts, they might misallocate their resources. For example, if they predominantly have larger vehicles in their fleet but most rides involve single passengers, it could lead to inefficiency and increased operational costs.\n",
        "\n",
        "**Poor Customer Experience:** If the service does not align with the typical passenger count, customers might have a poor experience. For instance, if a customer books a taxi assuming it can accommodate a group of 6, but the majority of the fleet consists of smaller cars, it can lead to dissatisfaction and negative reviews."
      ],
      "metadata": {
        "id": "HscOWxnOdjGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We can notice that most trips are booked by single person or we can say that less number of trips are booked by group of people.which means that trips are preffered by single person."
      ],
      "metadata": {
        "id": "9zC_61jXaGyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chart-6"
      ],
      "metadata": {
        "id": "oQOJMjbOYZ3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group the data by the categorized trip durations and count the number of trips in each category.\n",
        "\n"
      ],
      "metadata": {
        "id": "7ppZr8in1xfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code.\n",
        "\n",
        "# Define the bin boundaries and labels for categorizing trip durations.\n",
        "bins = [0, 1, 10, 30, 60, 1440, 1440*2, 50000]\n",
        "labels = ['<1 min', '1-10 mins', '10-30 mins', '30-60 mins', '1-24 hrs', '1-2 days', '2+ days']\n",
        "\n",
        "# Categorize the trip durations based on the defined bins and labels\n",
        "taxi_df['trip_duration_category'] = pd.cut(taxi_df['trip_duration_in_minute'], bins=bins, labels=labels)\n",
        "\n",
        "# Group the data by the categorized trip durations and count the number of trips in each category\n",
        "trip_duration_counts = taxi_df['trip_duration_category'].value_counts()\n",
        "\n",
        "# Create a bar plot using the grouped and counted data\n",
        "plt.figure(figsize=[10, 5])\n",
        "trip_duration_counts.sort_index().plot(kind='bar', color='skyblue', edgecolor='black')\n",
        "\n",
        "# Add title and labels to the plot\n",
        "plt.title('Distribution of Trip Durations')\n",
        "plt.xlabel('Trip Duration')\n",
        "plt.ylabel('Number of Trips')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Annotate the bars with exact values\n",
        "for i, v in enumerate(trip_duration_counts.sort_index()):\n",
        "    plt.text(i, v + 50, str(v), ha='center', va='bottom')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xqq9lXnmpf_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Why did you pick the specific chart?**"
      ],
      "metadata": {
        "id": "rMyraD5EALFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the bin boundaries and labels for categorizing trip durations.\n",
        "bins = [0, 1, 10, 30, 60, 1440, 1440*2, 50000]\n",
        "labels = ['<1 min', '1-10 mins', '10-30 mins', '30-60 mins', '1-24 hrs', '1-2 days', '2+ days']\n",
        "\n",
        "# Categorize the trip durations based on the defined bins and labels\n",
        "taxi_df['trip_duration_category'] = pd.cut(taxi_df['trip_duration_in_minute'], bins=bins, labels=labels)\n",
        "\n",
        "# Group the data by the categorized trip durations and count the number of trips in each category\n",
        "trip_duration_counts = taxi_df['trip_duration_category'].value_counts()\n",
        "\n",
        "# Create a bar plot using the grouped and counted data\n",
        "plt.figure(figsize=[10, 5])\n",
        "trip_duration_counts.sort_index().plot(kind='bar', color='skyblue', edgecolor='black')\n",
        "\n",
        "# Add title and labels to the plot\n",
        "plt.title('Distribution of Trip Durations')\n",
        "plt.xlabel('Trip Duration')\n",
        "plt.ylabel('Number of Trips')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Annotate the bars with exact values\n",
        "for i, v in enumerate(trip_duration_counts.sort_index()):\n",
        "    plt.text(i, v + 50, str(v), ha='center', va='bottom')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L01urWWQvxzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Answer Here.**\n",
        "\n",
        "Bar chart to visualize the distribution of trip durations in different categories. Here's why this choice makes sense:\n",
        "\n",
        "**Categorical Data Representation:** The data is categorized into different duration ranges such as '<1 min', '1-10 mins', '10-30 mins' and so on. Bar charts are excellent for representing categorical data, where each category can be represented by a distinct bar.\n",
        "\n",
        "**Counting Frequencies:** The chart displays the number of trips in each duration category. Bar charts are commonly used to represent frequencies or counts of categorical data, making it easy to understand the distribution of trips across various durations.\n",
        "\n",
        "**Comparative Analysis:** Bar charts allow for easy comparison between different categories. In this case, it enables a clear visual comparison of the number of trips for each duration category."
      ],
      "metadata": {
        "id": "CjMObqqmdxuI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **2. What is/are the insight(s) found from the chart?**"
      ],
      "metadata": {
        "id": "tmOc13uHdxhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the bin boundaries and labels for categorizing trip durations.\n",
        "bins = [0, 1, 10, 30, 60, 1440, 1440*2, 50000]\n",
        "labels = ['<1 min', '1-10 mins', '10-30 mins', '30-60 mins', '1-24 hrs', '1-2 days', '2+ days']\n",
        "\n",
        "# Categorize the trip durations based on the defined bins and labels\n",
        "taxi_df['trip_duration_category'] = pd.cut(taxi_df['trip_duration_in_minute'], bins=bins, labels=labels)\n",
        "\n",
        "# Group the data by the categorized trip durations and count the number of trips in each category\n",
        "trip_duration_counts = taxi_df['trip_duration_category'].value_counts()\n",
        "\n",
        "# Create a bar plot using the grouped and counted data\n",
        "plt.figure(figsize=[10, 5])\n",
        "trip_duration_counts.sort_index().plot(kind='bar', color='skyblue', edgecolor='black')\n",
        "\n",
        "# Add title and labels to the plot\n",
        "plt.title('Distribution of Trip Durations')\n",
        "plt.xlabel('Trip Duration')\n",
        "plt.ylabel('Number of Trips')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Annotate the bars with exact values\n",
        "for i, v in enumerate(trip_duration_counts.sort_index()):\n",
        "    plt.text(i, v + 50, str(v), ha='center', va='bottom')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yXlkSFKRvzxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "Analyzing the distribution of trip durations for the NYC Taxi Trip Time Prediction dataset and categorizing the trip durations into different bins. Based on the provided bin boundaries and labels, the chart displays the number of trips falling into each category of trip duration.\n",
        "\n",
        "**Most Trips are Short:** The majority of trips fall within the '<10 mins' category, indicating that a significant portion of taxi rides are short-distance travels.\n",
        "\n",
        "**Relatively Few Long-Distance Trips:** There are relatively fewer trips in the '10-30 mins', '30-60 mins', '1-24 hrs', '1-2 days', and '2+ days' categories. This suggests that long-duration trips are not as common as shorter trips.\n",
        "\n",
        "**Negligible Long-Duration Trips:** The categories '1-24 hrs', '1-2 days', and '2+ days' show very few or negligible trips, indicating that extremely long-duration taxi rides are rare in the dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BgIqsxWXdxPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### **3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason.**"
      ],
      "metadata": {
        "id": "ZTNVTsVldxD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Answer Here.**\n",
        "\n",
        "The trip durations from the NYC Taxi Trip Time Prediction dataset into specific bins (such as less than 1 minute, 1-10 minutes, 10-30 minutes, etc.) and then visualizes the distribution of trips in these duration categories using a bar plot. This analysis can provide valuable insights that can potentially lead to positive business impacts and help identify areas for improvement.\n",
        "\n",
        "\n",
        "**Positive Business Impact:**\n",
        "\n",
        "**Demand Analysis:** By understanding the distribution of trip durations, taxi companies can optimize their fleet management. For instance, if there is a high demand for short trips (less than 10 minutes), companies might consider introducing smaller vehicles that are more fuel-efficient, leading to cost savings.\n",
        "\n",
        "**Pricing Strategy:** Companies can adjust their pricing strategies based on the trip durations. Short trips might have a different pricing model compared to longer trips, and understanding the distribution helps in setting competitive and profitable prices.\n",
        "\n",
        "**Service Improvement:** Understanding the distribution can highlight areas where service improvement is needed. For instance, if there are a significant number of long-duration trips, companies might focus on providing amenities like in-car entertainment, comfortable seating, or Wi-Fi to enhance customer satisfaction during these journeys.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a3IPWuGGdwvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* By above chart we can say that most of the trip duration is within 10 and 30 minutes.\n",
        "* Few trips are within 30 to 60 minutes.\n",
        "* Rarely trips are within a day."
      ],
      "metadata": {
        "id": "yFmOtVIHlvhS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chart-7"
      ],
      "metadata": {
        "id": "peIhRJu7bB0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For visually comparing the distributions and central tendencies (mean and median) of different numeric features in the \"taxi_df\" DataFrame using histograms and box plots.Iterate through each numeric feature in the DataFrame.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZXydXb0_13Ru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distribution of different features\n"
      ],
      "metadata": {
        "id": "zH6EqpMNnl5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "\n",
        "# Histplots and boxplots to determine the distribution of the data given below.\n",
        "numeric_feature=['passenger_count','Distance','trip_duration_in_minute','pickup_hour','dropoff_hour']\n",
        "numeric_feature"
      ],
      "metadata": {
        "id": "fKjVn0fCRBGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taxi_df[\"Distance\"] = taxi_df[\"Distance\"].astype(float)"
      ],
      "metadata": {
        "id": "ZRu42rt3T3A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code snippet is useful for visually comparing the distributions and central tendencies (mean and median) of different numeric features in the \"taxi_df\" DataFrame using histograms and box plots.\n",
        "# Iterate through each numeric feature in the DataFrame.\n",
        "for col in numeric_feature:\n",
        "    # Create a figure with one row and two columns, representing two subplots side by side.\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
        "\n",
        "    # Plot a histogram for the current numeric feature in the first subplot (index 0).\n",
        "    sns.histplot(data=taxi_df, x=col, ax=ax[0], kde=True, color='skyblue')\n",
        "    # Add vertical lines for mean and median to the histogram plot.\n",
        "    ax[0].axvline(taxi_df[col].mean(), color='magenta', linestyle='dashed', linewidth=2, label='Mean')\n",
        "    ax[0].axvline(taxi_df[col].median(), color='cyan', linestyle='dashed', linewidth=2, label='Median')\n",
        "    # Set plot title and labels.\n",
        "    ax[0].set_title(f'Distribution of {col}')\n",
        "    ax[0].set_xlabel(col)\n",
        "    ax[0].legend()  # Show legend for mean and median lines.\n",
        "\n",
        "    # Create a boxplot for the current numeric feature in the second subplot (index 1).\n",
        "    sns.boxplot(data=taxi_df, x=col, ax=ax[1], color='lightgreen')\n",
        "    # Add vertical lines for mean and median to the boxplot.\n",
        "    ax[1].axvline(taxi_df[col].mean(), color='magenta', linestyle='dashed', linewidth=2, label='Mean')\n",
        "    ax[1].axvline(taxi_df[col].median(), color='cyan', linestyle='dashed', linewidth=2, label='Median')\n",
        "    # Set plot title and labels.\n",
        "    ax[1].set_title(f'Boxplot of {col}')\n",
        "    ax[1].set_xlabel(col)\n",
        "    ax[1].legend()  # Show legend for mean and median lines.\n",
        "\n",
        "    plt.tight_layout()  # Adjust layout for a better visualization spacing.\n",
        "\n",
        "    # Display the plots for the current numeric feature.\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "0SgjbXa_RA-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Why did you pick the specific chart?**"
      ],
      "metadata": {
        "id": "mAeSBDjEANFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        " The left subplot (index 0) shows the distribution of the numeric feature using a histogram, while the right subplot (index 1) shows the same distribution using a box plot.\n",
        "\n",
        "\n",
        " The specific charts (histogram and box plot) were chosen for the following reasons:\n",
        "\n",
        "**Histogram:**\n",
        "\n",
        "**Purpose:** Histograms are useful for visualizing the distribution of a single variable. They show the frequency or count of data points within specific intervals (bins) along the numerical range.\n",
        "\n",
        "\n",
        "**Use Case:** Histograms are effective for understanding the shape of the distribution, identifying patterns (such as normal or skewed distributions), and detecting outliers.\n",
        "\n",
        "\n",
        "**Box Plot:**\n",
        "\n",
        "**Purpose:** Box plots (box-and-whisker plots) are excellent for visualizing the summary statistics of a dataset, including the median, quartiles, and potential outliers.\n",
        "\n",
        "**Use Case:** Box plots provide a clear summary of the central tendency (median) and the spread of the data. They are particularly useful for comparing the distributions of multiple variables or groups."
      ],
      "metadata": {
        "id": "vFoxgbWqeEIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **2. What is/are the insight(s) found from the chart?**"
      ],
      "metadata": {
        "id": "0did00pdeD7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "The histograms, you can observe the shape of the data distribution. If the distribution is symmetric, skewed to the left, or skewed to the right, it can indicate different patterns in the data.\n",
        "\n",
        "**Symmetric Distribution:** If the histogram is roughly symmetric, it suggests that the data is balanced and evenly distributed.\n",
        "\n",
        "**Skewed to the Left (Negatively Skewed):** If the left tail (where the smaller values are) is longer or fatter than the right tail, the data is skewed to the left. In the context of taxi trip time prediction, this might mean that most trips have longer durations.\n",
        "\n",
        "**Skewed to the Right (Positively Skewed):** If the right tail (where the larger values are) is longer or fatter than the left tail, the data is skewed to the right. In the context of taxi trip time prediction, this might mean that most trips have shorter durations.\n",
        "\n",
        "From the box plots, you can identify outliers and get a sense of the spread of the data. Outliers are data points that significantly differ from most other observations and can indicate interesting phenomena or errors in the data collection process.\n",
        "\n",
        "The vertical lines in both the histograms and box plots represent the mean (magenta) and median (cyan) values. Comparing the mean and median can provide insights into the skewness of the data. If mean > median, the data is skewed to the right; if mean < median, the data is skewed to the left."
      ],
      "metadata": {
        "id": "Y7s25e8leDr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "#### **3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason.**\n"
      ],
      "metadata": {
        "id": "EahmgNIYeDfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Answer Here.**\n",
        "\n",
        "**Positive Business Impact:**\n",
        "\n",
        "\n",
        "**Identifying Patterns:** By comparing histograms and box plots, you can identify patterns in the data. For instance, if the trip duration shows a consistent pattern (like most trips being short), businesses can strategize accordingly. Short trips might lead to more frequent turnovers, allowing for higher profits if managed efficiently.\n",
        "\n",
        "**Optimizing Services:** Understanding peak usage times (via time-related features) can help in optimizing taxi services. If there's a visible peak during rush hours, businesses can allocate more resources (taxis and drivers) during those times, ensuring better service for customers and potentially increasing revenue.\n",
        "\n",
        "**Customer Preferences:** If certain features like trip distance or fare amount have distinctive peaks or trends, businesses can tailor their marketing strategies. For example, if there are more long-distance trips during weekends, special weekend promotions could be introduced to attract more customers during those periods.\n",
        "\n",
        "**Negative Growth:**\n",
        "\n",
        "**Outliers and Anomalies:** If these visualizations reveal extreme outliers (for example, unusually high fares for short trips), it might indicate fraudulent activities or errors in the billing system. Addressing such issues promptly is crucial; failure to do so could lead to financial losses and damage the company's reputation.\n",
        "\n",
        "**Inefficiencies:** If there are unexpected distributions or trends, it might indicate inefficiencies in the business process. For instance, if the trip duration is significantly higher than expected for certain routes, it could imply issues such as traffic congestion or inefficient route planning. Addressing these inefficiencies is vital to providing better services and optimizing costs."
      ],
      "metadata": {
        "id": "iuQwVLAmeDXN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The histograms for distance and trip duration indicate significant skewness, while the box plots for these columns reveal the presence of numerous outliers."
      ],
      "metadata": {
        "id": "Z7wHLIWrkApU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chart-8\n",
        "# **Heatmap**"
      ],
      "metadata": {
        "id": "Nam2raqQdeTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Correlation Heatmap** - Generates a heatmap to visualize the correlation matrix of the NYC Taxi Trip Time Prediction dataset.\n"
      ],
      "metadata": {
        "id": "zvK5lzOY18pU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "# Set the size of the figure\n",
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation = taxi_df.corr()\n",
        "\n",
        "# Choose a color palette (for example, \"coolwarm\")\n",
        "cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
        "\n",
        "# Create the heatmap with annotations, using a diverging color palette\n",
        "sns.heatmap(correlation, annot=True, cmap=cmap, fmt=\".2f\", linewidths=1, vmin=-1, vmax=1)\n",
        "\n",
        "# Set plot title and labels for axes\n",
        "plt.title(\"Correlation Matrix Heatmap\", fontsize=16)\n",
        "plt.xlabel(\"Features\", fontsize=14)\n",
        "plt.ylabel(\"Features\", fontsize=14)\n",
        "\n",
        "# Increase font size of annotations for better readability\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YEozpTIYZ9J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Why did you pick the specific chart?**\n"
      ],
      "metadata": {
        "id": "mZvHaENKAPbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Answer Here.**\n",
        "\n",
        "The code you provided generates a heatmap to visualize the correlation matrix of the NYC Taxi Trip Time Prediction dataset.\n",
        "\n",
        "**Correlation Analysis:** The purpose of this chart is to understand the relationships between different variables in the dataset. Heatmaps are excellent for displaying correlation matrices because they use color to represent the strength and direction of the relationships. Positive correlations are often displayed in one color (e.g., shades of blue), while negative correlations are shown in another color (e.g., shades of red). This makes it easy to identify patterns and relationships in the data."
      ],
      "metadata": {
        "id": "7BJpTdFTedrk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2. What is/are the insight(s) found from the chart?**"
      ],
      "metadata": {
        "id": "mqYqFl5Fede0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Answer Here.**\n",
        "\n",
        "In this heatmap, correlation coefficients between different pairs of features are represented by colors, where values close to 1 indicate a strong positive correlation, values close to -1 indicate a strong negative correlation, and values close to 0 indicate a weak or no correlation.\n",
        "\n",
        "**Positive Correlations with Trip Time:**\n",
        "\n",
        "**Distance:** Typically, the distance of the trip and the duration of the trip have a strong positive correlation. Longer distances usually mean longer trip times.\n",
        "\n",
        "\n",
        "**Pickup/Dropoff Coordinates:** The longitude and latitude coordinates of the pickup and dropoff locations might be positively correlated with trip duration. For example, trips from downtown areas to airports might take longer."
      ],
      "metadata": {
        "id": "T0Vg502DedSE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* By above heatmap it visualize that pickup_month and dropoff month is 100% correlated. Along with pickup hour, dropoff hour,pickup weekday and dropoff week day, trip duration in minute are highly correlated."
      ],
      "metadata": {
        "id": "OrQHtOwbYffO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pair plot**"
      ],
      "metadata": {
        "id": "rkM-Bj-Vr_op"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pair Plot**- A pair plot is a grid of scatterplots, where variables are plotted against each other. If you have a dataset with multiple numeric variables, a pair plot allows you to visualize the relationships between these variables."
      ],
      "metadata": {
        "id": "_3zPt5hu2CCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "\n",
        "# Pair Plot\n",
        "sns.pairplot(taxi_df, hue=\"trip_duration_in_minute\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1HIFuM6lq_qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Why did you pick the specific chart?**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sKY1LhAQAUAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Answer Here.**\n",
        "\n",
        "A pair plot is a grid of scatterplots, where variables are plotted against each other. If you have a dataset with multiple numeric variables, a pair plot allows you to visualize the relationships between these variables.\n",
        "\n",
        "**Multivariate Exploration:** Pair plots allow you to explore relationships between multiple variables at once. For instance, in the context of a taxi dataset, you might want to see how different variables like distance, passenger count, or time of day relate to the trip duration. A pair plot can help you quickly identify potential patterns or correlations."
      ],
      "metadata": {
        "id": "R73sUJiXeora"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "#### **2. What is/are the insight(s) found from the chart?**"
      ],
      "metadata": {
        "id": "CUpsrM8_epYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Answer Here.**\n",
        "\n",
        "A pair plot is a grid of scatterplots that allows you to visualize relationships between different pairs of variables. If the \"trip_duration\" variable is used as the hue, it could provide insights into how trip duration relates to other features in the dataset.\n",
        "\n",
        "**Correlations:** You can identify positive or negative correlations between \"trip_duration\" and other variables. For instance, if you see a diagonal line sloping upwards from the bottom left to the top right, it indicates a positive correlation. Conversely, a downward slope indicates a negative correlation."
      ],
      "metadata": {
        "id": "O9nYwq9Nep-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correlated(dataset,thresold):\n",
        "  corr_column = set() # all the highly correlated column\n",
        "  for i in range(len(correlation.columns)):\n",
        "    for j in range(i):\n",
        "      if abs(correlation.iloc[i,j])>=thresold:  # We want absolute value\n",
        "        column_name=correlation.columns[i]      # getting the name of columns\n",
        "        corr_column.add(column_name)            # add the name column in empty set\n",
        "  return corr_column"
      ],
      "metadata": {
        "id": "JND2_npNZ7_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling the function with thresold value 0.90\n",
        "highly_correlated_features = correlated(taxi_df,0.90)\n",
        "print('total highly correlted features:',len(set(highly_correlated_features)))"
      ],
      "metadata": {
        "id": "Osaj8ZhjZ7qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "highly_correlated_features"
      ],
      "metadata": {
        "id": "gGOThwkSqPX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Based on the analysis above, it can be concluded that there are four columns exhibiting a strong correlation of over 90%.\n",
        "\n",
        "* Removing highly correlated features leads to improved performance."
      ],
      "metadata": {
        "id": "XjvabDXVqYhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examining the asymmetry of the target variable."
      ],
      "metadata": {
        "id": "ZVpmxGcxrHGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dist plot of trip duration.\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
        "\n",
        "# Plotting the original trip duration\n",
        "sns.distplot(taxi_df.trip_duration, color='red', ax=ax[0], hist=False, kde_kws={'shade': True, 'linewidth': 2})\n",
        "\n",
        "# Plotting the trip duration after applying log transformation\n",
        "sns.distplot(np.log10(taxi_df['trip_duration']), color='green', ax=ax[1], hist=False, kde=True, kde_kws={'shade': True, 'linewidth': 2})\n",
        "\n",
        "ax[1].set_title('Distribution after applying log transformation')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jtMeParpUTOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* By above distribution we can clearly see that target variable is highly right skewed to remove the skewness we apply log transformation after transformation we found normal distribution of target variable."
      ],
      "metadata": {
        "id": "Zb-qYdghw_9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "uqOic9Q5xSqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "4wzhdh3PxSqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "# No Missing/Null Values in the Data Set"
      ],
      "metadata": {
        "id": "26aHUlqmxSqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "h0XeNK4qxSqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "pIjEl0bMxSqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "J1RXh4R9xSqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eliminating exceptional data points(Quartile Method)\n",
        "**Interquartile range measures the spread of the middle half of our data.**\n",
        "\n",
        "**Formula=Q3-Q1**\n",
        "\n",
        "**where Q1- quartile 1 and Q3- quartile 3**\n",
        "\n",
        "**lower limit of the data is given by Q1-1.5*IQR**\n",
        "\n",
        "**Upper limit of the data is given by Q3 + 1.5IQR**"
      ],
      "metadata": {
        "id": "TIgnCFxOx4Co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments.\n",
        "\n",
        "# Create a figure with a single row and three columns of subplots.\n",
        "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(18, 5))\n",
        "\n",
        "# Create a box plot for the 'trip_duration' column and place it in the first subplot.\n",
        "sns.boxplot(x=taxi_df['trip_duration'], ax=ax[0], orient='v', color='skyblue', width=0.5)\n",
        "ax[0].set_title('Trip Duration Distribution')  # Set title for the subplot.\n",
        "ax[0].set_xlabel('Duration (seconds)')  # Set x-axis label.\n",
        "ax[0].grid(True, linestyle='--', linewidth=0.5)  # Add grid lines.\n",
        "\n",
        "# Create a box plot for the 'passenger_count' column and place it in the second subplot.\n",
        "sns.boxplot(x=taxi_df['passenger_count'], ax=ax[1], orient='v', color='lightgreen', width=0.5)\n",
        "ax[1].set_title('Passenger Count Distribution')  # Set title for the subplot.\n",
        "ax[1].set_xlabel('Number of Passengers')  # Set x-axis label.\n",
        "ax[1].grid(True, linestyle='--', linewidth=0.5)  # Add grid lines.\n",
        "\n",
        "# Create a box plot for the 'distance' column and place it in the third subplot.\n",
        "sns.boxplot(x=taxi_df['Distance'], ax=ax[2], orient='v', color='lightcoral', width=0.5)\n",
        "ax[2].set_title('Distance Distribution')  # Set title for the subplot.\n",
        "ax[2].set_xlabel('Distance (miles)')  # Set x-axis label.\n",
        "ax[2].grid(True, linestyle='--', linewidth=0.5)  # Add grid lines.\n",
        "\n",
        "# Rotate y-axis labels to horizontal for easier reading.\n",
        "for axis in ax:\n",
        "    axis.tick_params(axis='y', rotation=0)\n",
        "\n",
        "# Add spacing between subplots and show the plot.\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yHEpdyRfeZzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding differnt quarters of trip_duration column.\n",
        "trip_duration_Q1 = taxi_df['trip_duration'].quantile(0.25)\n",
        "print('first quartile value ie 25th percentile of trip duration:',trip_duration_Q1)\n",
        "trip_duration_Q2 = taxi_df['trip_duration'].quantile(0.50)\n",
        "print('second quartile value ie 50th percentile of trip duration:',trip_duration_Q2)\n",
        "trip_duration_Q3 = taxi_df['trip_duration'].quantile(0.75)\n",
        "print('third quartile value ie 75th percentile of trip duration:',trip_duration_Q3)"
      ],
      "metadata": {
        "id": "DJJrCs3FqPN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Inquartile range.\n",
        "IQR=trip_duration_Q3-trip_duration_Q1\n",
        "print('IQR:',IQR)\n",
        "trip_duration_lower_limit=trip_duration_Q1-1.5*IQR\n",
        "trip_duration_upper_limit=trip_duration_Q3+1.5*IQR\n",
        "print('The lower limit of trip duration:',trip_duration_lower_limit)\n",
        "print('The upper limit of trip duration:',trip_duration_upper_limit)"
      ],
      "metadata": {
        "id": "nEVL0ll9qPK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing outliers in trip_duration features.\n",
        "taxi_df=taxi_df[taxi_df['trip_duration']>0]\n",
        "taxi_df=taxi_df[taxi_df['trip_duration']<trip_duration_upper_limit]"
      ],
      "metadata": {
        "id": "2eO9KoBFqO-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding different quarters of passenger_count column\n",
        "passenger_count_Q1=taxi_df['passenger_count'].quantile(0.25)\n",
        "print('first quartile value ie 25th percentile of passenger count:',passenger_count_Q1)\n",
        "passenger_count_Q2=taxi_df['passenger_count'].quantile(0.50)\n",
        "print('second quartile value ie 50th percentile of passenger count:',passenger_count_Q2)\n",
        "passenger_count_Q3=taxi_df['passenger_count'].quantile(0.75)\n",
        "print('third quartile value ie 75th percentile of passenger count:',passenger_count_Q3)"
      ],
      "metadata": {
        "id": "LDWyTJhYcyPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate IQR\n",
        "IQR=passenger_count_Q3 - passenger_count_Q1\n",
        "print('IQR:',IQR)\n",
        "passenger_count_lower_limit=passenger_count_Q1-1.5*IQR\n",
        "passenger_count_upper_limit=passenger_count_Q3+1.5*IQR\n",
        "print('The lower limit of passenger count:',passenger_count_lower_limit)\n",
        "print('The upper limit of passenger count:',passenger_count_upper_limit)"
      ],
      "metadata": {
        "id": "GgOoZF_ic320"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering out rows with trip durations less than or equal to 0\n",
        "taxi_df = taxi_df[taxi_df['trip_duration_in_minute'] > 0]\n",
        "\n",
        "# Filtering out rows with trip durations greater than the defined upper limit\n",
        "# This is done to remove outliers in the 'trip_duration_in_minute' feature\n",
        "taxi_df = taxi_df[taxi_df['trip_duration_in_minute'] < passenger_count_upper_limit]"
      ],
      "metadata": {
        "id": "THjHROV_c_yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the taxi dataset into a DataFrame (taxi_df)\n",
        "# Make sure you have loaded the dataset before running this code\n",
        "\n",
        "# Calculating the first quartile (25th percentile) of the 'distance' column\n",
        "distance_count_Q1 = taxi_df['Distance'].quantile(0.25)\n",
        "# Printing the calculated first quartile value\n",
        "print('first quartile value ie 25th percentile of distance count:', distance_count_Q1)\n",
        "\n",
        "# Calculating the second quartile (50th percentile/median) of the 'distance' column\n",
        "distance_count_Q2 = taxi_df['Distance'].quantile(0.50)\n",
        "# Printing the calculated second quartile value\n",
        "print('second quartile value ie 50th percentile of distance count:', distance_count_Q2)\n",
        "\n",
        "# Calculating the third quartile (75th percentile) of the 'distance' column\n",
        "distance_count_Q3 = taxi_df['Distance'].quantile(0.75)\n",
        "# Printing the calculated third quartile value\n",
        "print('third quartile value ie 75th percentile of distance count:', distance_count_Q3)"
      ],
      "metadata": {
        "id": "8tC0SuO4dH0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the Interquartile Range (IQR)\n",
        "# IQR is the range between the 1st quartile (Q1) and the 3rd quartile (Q3)\n",
        "IQR = distance_count_Q3 - distance_count_Q1\n",
        "print('IQR:', IQR)  # Print the calculated IQR\n",
        "\n",
        "# Calculate the lower and upper limits for outlier detection\n",
        "# The lower limit is calculated as Q1 - 1.5 * IQR\n",
        "distance_duration_lower_limit = distance_count_Q1 - 1.5 * IQR\n",
        "# The upper limit is calculated as Q3 + 1.5 * IQR\n",
        "distance_duration_upper_limit = distance_count_Q3 + 1.5 * IQR\n",
        "\n",
        "# Print the calculated lower and upper limits for distance duration\n",
        "print('The lower limit of distance duration:', distance_duration_lower_limit)\n",
        "print('The upper limit of distance duration:', distance_duration_upper_limit)"
      ],
      "metadata": {
        "id": "7QaFZ-01dS11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing outliers in the 'trip_duration_in_minute' feature\n",
        "\n",
        "# Filter out rows where trip duration is less than or equal to 0\n",
        "taxi_df = taxi_df[taxi_df['trip_duration_in_minute'] > 0]\n",
        "\n",
        "# Filter out rows where trip duration exceeds the upper limit defined by 'distance_duration_upper_limit'\n",
        "taxi_df = taxi_df[taxi_df['trip_duration_in_minute'] < distance_duration_upper_limit]\n",
        "\n",
        "# At this point, 'taxi_df' contains data with outliers removed from the 'trip_duration_in_minute' feature"
      ],
      "metadata": {
        "id": "V7zw-l0Vdefw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Earlier we saw that distance and trip duratin had highly skewed graph....lets check the distribution again.\n",
        "# Create a figure with two subplots side by side\n",
        "figure, ax = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n",
        "\n",
        "# Plotting the distribution of the 'distance' column on the first subplot\n",
        "sns.distplot(\n",
        "    taxi_df['Distance'],                  # Data from the 'distance' column\n",
        "    hist=False,                           # Do not display histogram bars\n",
        "    kde=True,                             # Display kernel density estimate\n",
        "    kde_kws={'shade': True, 'linewidth': 2},  # Styling for the KDE plot\n",
        "    color='green',                        # Color of the plot\n",
        "    ax=ax[0]                              # Place the plot on the first subplot\n",
        ")\n",
        "# Adding a title to the first subplot\n",
        "ax[0].set_title('Distribution of Distance')\n",
        "\n",
        "# Plotting the distribution of the 'trip_duration' column on the second subplot\n",
        "sns.distplot(\n",
        "    taxi_df['trip_duration'],             # Data from the 'trip_duration' column\n",
        "    hist=False,                           # Do not display histogram bars\n",
        "    kde=True,                             # Display kernel density estimate\n",
        "    kde_kws={'shade': True, 'linewidth': 2},  # Styling for the KDE plot\n",
        "    color='green',                        # Color of the plot\n",
        "    ax=ax[1]                              # Place the plot on the second subplot\n",
        ")\n",
        "# Adding a title to the second subplot\n",
        "ax[1].set_title('Distribution of Trip Duration')\n",
        "\n",
        "# Display the final plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TP2ediT0dqTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "JG8R8_3FxSqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here.**\n",
        "\n",
        " I have used the Interquartile range(IQR) method to identift and remove outliers in the continuous columns of the dataset.I chose to use this technique because this is robust method to detect the outliers that is not affected by the presence of extreme values. The IQR is calculated as the 75th and 25th percentile of the data, and any value that falls between 25th percentile minus 1.5 times the IQR or above the 75th percentile plus 1.5 times the IQR is considered an outlier. By using this method.I was able to identify and remove outliers in a consistent and objective manner."
      ],
      "metadata": {
        "id": "qDQGRoyoxSqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Textual Data Preprocessing\n",
        "### ONE HOT ENCODING"
      ],
      "metadata": {
        "id": "0vZ3kGdFxSqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add dummy variable to convert textual data to numerical data through one hot encoding.\n",
        "taxi_df=pd.get_dummies(taxi_df,columns=[ 'pickup_weekday', 'pickup_month'],drop_first=True)"
      ],
      "metadata": {
        "id": "QxwbQuZ840kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "\n",
        "# Plotting the pie charts for binary categorical variables.\n",
        "plt.figure(figsize=(18, 12))\n",
        "\n",
        "rows = 5\n",
        "cols = 3\n",
        "count = 1\n",
        "Features_list = ['vendor_id', 'store_and_fwd_flag', 'pickup_weekday_1', 'pickup_weekday_2', 'pickup_weekday_3',\n",
        "                 'pickup_weekday_4', 'pickup_weekday_5', 'pickup_weekday_6',\n",
        "                 'pickup_month_2.0', 'pickup_month_3.0', 'pickup_month_4.0', 'pickup_month_5.0', 'pickup_month_6.0']\n",
        "\n",
        "LABELS = ['1','2']\n",
        "labels = ['Not pickup %','Pickup %']\n",
        "colors = ['#66b3ff', '#99ff99']\n",
        "\n",
        "for var in Features_list:\n",
        "    plt.subplot(rows, cols, count)\n",
        "    counts = taxi_df[var].value_counts()\n",
        "    if var=='vendor_id':\n",
        "      plt.pie(counts, labels=LABELS, autopct='%1.1f%%', colors=colors, startangle=90, wedgeprops={'edgecolor': 'white'})\n",
        "    else:\n",
        "      plt.pie(counts, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90, wedgeprops={'edgecolor': 'white'})\n",
        "    plt.title(f'Distribution of {var.replace(\"_\", \" \").title()}', fontsize=14)\n",
        "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "    count += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hCabqGfoJXPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "Glm1qoFnxSqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here.**\n",
        "\n",
        "Onehot encoding is used to encode the 'pickup_weekday', 'pickup_month' columns.All the remaining cateorical columns are binary(0/1) so no need to encode them."
      ],
      "metadata": {
        "id": "NcsV4C7jxSqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "vB0ZRMtTxSqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "zA5lVmYWxSqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Already done"
      ],
      "metadata": {
        "id": "i7DCdggCxSqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "W2E7v2AtxSqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "corr=taxi_df.corr()\n",
        "plt.figure(figsize=(25,10))\n",
        "sns.heatmap(corr,annot=True, cmap=plt.cm.Accent_r)"
      ],
      "metadata": {
        "id": "eaO_f7cMAl7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping excess columns\n",
        "taxi_df.drop(columns=['id',\"trip_duration\", 'dropoff_weekday',\"pickup_datetime\",\"dropoff_datetime\",'dropoff_day','pickup_day','pickup_hour','dropoff_hour','dropoff_weekday','dropoff_month'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "y8IOmoLTHLgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "corr=taxi_df.corr()\n",
        "plt.figure(figsize=(25,10))\n",
        "sns.heatmap(corr,annot=True, cmap=plt.cm.Accent_r)"
      ],
      "metadata": {
        "id": "tBWyMFjpxSqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used and why?"
      ],
      "metadata": {
        "id": "2lvm0ex8xSqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here.**\n",
        "\n",
        "The method we've used for feature selection is called correlation analysis.\n",
        " By selecting features that are moderately to strongly correlated with the target variable,we can avoid including irrelevant or redundant features in our model, reducing the risk of overfitting."
      ],
      "metadata": {
        "id": "Q43R7hjTxSqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "7wW_eDNwxSqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here.**\n",
        "\n",
        "'vendor_id', 'store_and_fwd_flag','passenger_count','distance','trip_duration_in_minute','pickup_day','pickup_weekday_1', 'pickup_weekday_2', 'pickup_weekday_3',\n",
        "                 'pickup_weekday_4', 'pickup_weekday_5', 'pickup_weekday_6',\n",
        "                 'pickup_month_2.0', 'pickup_month_3.0', 'pickup_month_4.0', 'pickup_month_5.0', 'pickup_month_6.0'\n",
        "\n",
        "Above features I found important as they correlation factor is low it means they are not correlated with each other.\n",
        "  Independence of Features: If two features are not correlated, it suggests that they are independent of each other. Independence is a crucial assumption for many machine learning algorithms. Features that are not correlated provide unique and independent information to the model. Including diverse and independent features can improve the model's ability to generalize to new, unseen data"
      ],
      "metadata": {
        "id": "cvXV7n8GxSqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "T5pItly8xSqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "wqX2uKr1xSqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "# creating the set of dependent and independent variables\n",
        "X = taxi_df.drop(labels='trip_duration_in_minute', axis=1)\n",
        "Y = taxi_df['trip_duration_in_minute']\n",
        "\n",
        "# print the shape of X and Y\n",
        "print(f\"The Number of Rows and Columns in X is {X.shape} respectively.\")\n",
        "print(f\"The Number of Rows and Columns in Y is {Y.shape} respectively.\")"
      ],
      "metadata": {
        "id": "6ZC2doXVxSqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "ABoy5LrwxSqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "lxsr_PquxSqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Oesrr9EvxSqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "1yfTgAZ-xSqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "kwkHLq61xSqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "kG68jMNWxSqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Data Splitting"
      ],
      "metadata": {
        "id": "2_w0jCLsxSqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# Importing train test split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "ZQ2VkLuqxSqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the shape of Train Test set.\n",
        "\n",
        "print(\"Training Dataset Shape:--\")\n",
        "print(\"X_train shape \", X_train.shape)\n",
        "print(\"Y_train shape \", Y_train.shape)\n",
        "print(\"Testing Dataset Shape:--\")\n",
        "print(\"X_test shape \",X_test.shape)\n",
        "print(\"Y_test shape \",Y_test.shape)"
      ],
      "metadata": {
        "id": "xobJ6Z8PYg6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "O5pezFooxSqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here.**\n",
        "\n",
        "In the given code, the data splitting ratio used is 80:20, meaning 80% of the data is used for training (X_train and Y_train), and 20% of the data is used for testing (X_test and Y_test). This ratio is determined by the test_size parameter, which is set to 0.2 (20%).An 80:20 split is a common and reasonable choice, especially when dealing with moderate to large-sized datasets. It allows for a substantial portion of the data to be used for training the model, while still retaining a separate portion for evaluating its performance."
      ],
      "metadata": {
        "id": "CQm_aOXvxSqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Scaling"
      ],
      "metadata": {
        "id": "ExSlu5ygxSqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "taxi_df.columns"
      ],
      "metadata": {
        "id": "RnTvAKIo5Gz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns"
      ],
      "metadata": {
        "id": "PNsZgmPf2Xj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "PfHm8cHby5bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "-XscIz19xSqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "not reqired"
      ],
      "metadata": {
        "id": "Rd4R2tUSzbh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "XV4WNkz1xSqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "aB5swBe7xSqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "X8peahg3xSqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "#Not needed"
      ],
      "metadata": {
        "id": "p80i9HEIxSqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "8BKku5acxSqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "o5jU-nP7xSql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "taxi_df.shape"
      ],
      "metadata": {
        "id": "iC5bnTyRoKOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "7YcxaJW6gP8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XG Boost.\n",
        "\n",
        "## Random Forest.\n",
        "\n",
        "## Decision Tree.\n",
        "\n",
        "## Gradient Boost.\n",
        "\n",
        "## Linear Regressor."
      ],
      "metadata": {
        "id": "MVn4qG6Y6MC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# define a  function to calculate evaluation metrics\n",
        "def regression_evaluation_metrics (x_train,y_train,y_predicted):\n",
        "  MSE=round(mean_squared_error(y_true=y_train, y_pred=y_predicted),4)\n",
        "  RMSE=math.sqrt(MSE)\n",
        "  R2_score=r2_score(y_true=y_train, y_pred=y_predicted)\n",
        "  Adjusted_R2_score=1-((1-( R2_score))*(x_train.shape[0]-1)/(x_train.shape[0]-x_train.shape[1]-1))\n",
        "\n",
        "  print(\"Mean Squared Error:\",MSE,\"Root Mean Squared Error:\", RMSE)\n",
        "  print(\"R2 Score :\",R2_score,\"Adjusted R2 Score :\",Adjusted_R2_score)\n",
        "  # plotting actual and predicted values\n",
        "  #Plotting Actual and Predicted Values\n",
        "\n",
        "  # Set the number of data points to visualize (for better clarity)\n",
        "  num_data_points = 100\n",
        "\n",
        "  # Plotting actual and predicted values for the first 100 data points\n",
        "  plt.figure(figsize=(12, 6))\n",
        "\n",
        "  # Plotting Predicted values in red\n",
        "  plt.plot(range(num_data_points), y_predicted[:num_data_points], color='red', marker='o', linestyle='-', linewidth=2, markersize=6, label='Predicted')\n",
        "\n",
        "  # Plotting Actual values in green\n",
        "  plt.plot(range(num_data_points), np.array(y_train)[:num_data_points], color='green', marker='o', linestyle='-', linewidth=2, markersize=6, label='Actual')\n",
        "\n",
        "  # Adding labels, title, legend, and grid for better interpretation\n",
        "  plt.xlabel('Data Points', fontsize=12)\n",
        "  plt.ylabel('Time Duration', fontsize=12)\n",
        "  plt.title('Actual vs. Predicted Time Duration', fontsize=14)\n",
        "  plt.legend(fontsize=10)\n",
        "  plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "  # Display only specific data points on the x-axis for better readability\n",
        "  plt.xticks(range(0, num_data_points, 10))\n",
        "\n",
        "  # Adding a horizontal line at y=0 for reference (assuming time duration cannot be negative)\n",
        "  plt.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.7)\n",
        "\n",
        "  # Annotate a specific point for emphasis (optional)\n",
        "  # plt.annotate('Example Annotation', xy=(50, 10), xytext=(30, 20), arrowprops=dict(facecolor='black', shrink=0.05))\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n",
        "\n",
        "  # Example metrics values (replace these with your actual values)\n",
        "  metrics_names = ['MSE', 'RMSE', 'R2 Score', 'Adjusted R2 Score']\n",
        "  metrics_values = [MSE, RMSE, R2_score, Adjusted_R2_score]  # Replace these with your calculated values\n",
        "\n",
        "  # Creating a DataFrame for metrics\n",
        "  metrics_df = pd.DataFrame(metrics_values, index=metrics_names, columns=['Metrics'])\n",
        "\n",
        "  # Plotting the metrics heatmap\n",
        "  plt.figure(figsize=(6, 4))\n",
        "  sns.heatmap(data=metrics_df, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "  plt.title('Evaluation Metrics')\n",
        "  plt.xlabel('Metrics')\n",
        "  plt.ylabel('')\n",
        "  plt.show()\n",
        "  return(MSE,RMSE,R2_score,Adjusted_R2_score)"
      ],
      "metadata": {
        "id": "i9QXmJQsYrGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of variables selected for machine learning analysis.\n",
        "ml_variables = [\n",
        "    'vendor_id',              # ID of the taxi vendor\n",
        "    'passenger_count',        # Number of passengers\n",
        "    'Distance',               # Distance of the trip\n",
        "    'pickup_longitude',       # Longitude of pickup location\n",
        "    'pickup_latitude',        # Latitude of pickup location\n",
        "    'dropoff_longitude',      # Longitude of drop-off location\n",
        "    'dropoff_latitude',       # Latitude of drop-off location\n",
        "    'store_and_fwd_flag',     # Flag indicating if the trip data was stored locally before sending to vendor\n",
        "    'pickup_weekday_1',       # Binary flag for Monday (1 if pickup on Monday, 0 otherwise)\n",
        "    'pickup_weekday_2',       # Binary flag for Tuesday (1 if pickup on Tuesday, 0 otherwise)\n",
        "    'pickup_weekday_3',       # Binary flag for Wednesday (1 if pickup on Wednesday, 0 otherwise)\n",
        "    'pickup_weekday_4',       # Binary flag for Thursday (1 if pickup on Thursday, 0 otherwise)\n",
        "    'pickup_weekday_5',       # Binary flag for Friday (1 if pickup on Friday, 0 otherwise)\n",
        "    'pickup_weekday_6'        # Binary flag for Saturday (1 if pickup on Saturday, 0 otherwise)\n",
        "]\n",
        "\n",
        "# These variables are selected based on their potential impact on predicting taxi trip duration.\n",
        "# 'vendor_id': The taxi company might affect service quality and trip durations.\n",
        "# 'passenger_count': More passengers could lead to longer trips.\n",
        "# 'distance': Longer distances generally result in increased trip durations.\n",
        "# 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude':\n",
        "#     Geographic coordinates influencing the distance and duration of the trip.\n",
        "# 'store_and_fwd_flag': Indicates whether the trip record was held in vehicle memory before sending to the vendor.\n",
        "# 'pickup_weekday\n"
      ],
      "metadata": {
        "id": "MI2uy6U3aBLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting specific columns (features) for machine learning from the training data\n",
        "# ml_variables contains the list of column names to be included in the analysis\n",
        "\n",
        "# Selecting relevant features from the training data (X_train)\n",
        "X_train = X_train[ml_variables]\n",
        "\n",
        "# Selecting the same set of relevant features from the test data (X_test)\n",
        "X_test = X_test[ml_variables]\n",
        "\n",
        "# Now, X_train and X_test only contain the columns specified in ml_variables\n",
        "# These selected features will be used for training and evaluating machine learning models\n"
      ],
      "metadata": {
        "id": "QcGfnFuCaA8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a score dataframes\n",
        "Regression_Metrics_Score_train = pd.DataFrame(index = ['MSE', 'RMSE', 'R2 Score', 'Adjusted R2 Score'])\n",
        "Regression_Metrics_Score_test = pd.DataFrame(index = ['MSE', 'RMSE', 'R2 Score', 'Adjusted R2 Score'])"
      ],
      "metadata": {
        "id": "AR9MQMYIPjGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ML Model - FIRST Linear Regressor.**"
      ],
      "metadata": {
        "id": "-2Z7fXv4gP8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "# Instantiate the Linear Regression Model\n",
        "linear_regression_model = LinearRegression()\n",
        "\n",
        "# Fit the Algorithm\n",
        "# Train the Linear Regression Model\n",
        "linear_regression_model.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "# Predict on the model\n",
        "# Calculate R-squared score for training data\n",
        "training_r2_score = linear_regression_model.score(X_train, Y_train)\n",
        "\n",
        "# Predictions on the training set\n",
        "train_predictions = linear_regression_model.predict(X_train)\n",
        "\n",
        "# Predictions on the test set\n",
        "test_predictions = linear_regression_model.predict(X_test)"
      ],
      "metadata": {
        "id": "mmNsscOFoX_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "YIXZStGNgP8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Evaluate the model on the training data\n",
        "print(\"Evaluation Metrics for Training Data:\")\n",
        "Regression_Metrics_Score_train['Linear Regression'] = regression_evaluation_metrics(X_train, Y_train, train_predictions)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "print(\"Evaluation Metrics for Test Data:\")\n",
        "Regression_Metrics_Score_test['Linear Regression'] = regression_evaluation_metrics(X_test, Y_test, test_predictions)"
      ],
      "metadata": {
        "id": "A3VsfB4fgP8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Regression_Metrics_Score_train"
      ],
      "metadata": {
        "id": "kTkmXR51QsEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Regression_Metrics_Score_test"
      ],
      "metadata": {
        "id": "NlW3mEmYUuqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion - The low R2 score and high MSE indicate that this algorithm is not appropriate for our model."
      ],
      "metadata": {
        "id": "FzMpNJgk4iqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model SECOND - Gradient Boost.**"
      ],
      "metadata": {
        "id": "zwvNPkeBgP8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "gradient_boost_model=GradientBoostingRegressor()\n",
        "\n",
        "# Fit the Algorithm\n",
        "gradient_boost_model.fit(X_train,Y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_preds_gradient_boost_test = gradient_boost_model.predict(X_test)\n",
        "y_pred_gradient_boost_train=gradient_boost_model.predict(X_train)"
      ],
      "metadata": {
        "id": "bh6Qoit-hPvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TAEfsraogP8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "#Evaluation metrics for Train set\n",
        "Regression_Metrics_Score_train['Gradient Boosting'] = regression_evaluation_metrics( X_train,Y_train,y_pred_gradient_boost_train)\n",
        "\n",
        "#Evaluation metrics for Test set\n",
        "Regression_Metrics_Score_test['Gradient Boosting'] =regression_evaluation_metrics(X_test,Y_test,y_preds_gradient_boost_test)"
      ],
      "metadata": {
        "id": "ieVa81WrgP8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Regression_Metrics_Score_train"
      ],
      "metadata": {
        "id": "bB6Nl7aeTFne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Regression_Metrics_Score_test"
      ],
      "metadata": {
        "id": "84O4FEDIVEfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Above algorithm has accuracy score:47% train, 43% test. which is higher that our previous algorithm (Linear Regressor)."
      ],
      "metadata": {
        "id": "eXJXHGb83USJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ML Model - THIRD Decision Tree.**"
      ],
      "metadata": {
        "id": "hos3V4sbgP8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Maximum depth of trees\n",
        "max_depth = [4,6,8,10,12]\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [10,20,30]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [6,10,16,20]\n",
        "\n",
        "# Hyperparameter Grid\n",
        "param_decision_tree = {\n",
        "              'max_depth' : max_depth,\n",
        "              'min_samples_split' : min_samples_split,\n",
        "              'min_samples_leaf' : min_samples_leaf}\n",
        "DTR = DecisionTreeRegressor()\n",
        "\n",
        "\n",
        "# Fit the Algorithm\n",
        "# Grid search\n",
        "decision_tree_grid = GridSearchCV(estimator=DTR,\n",
        "                       param_grid = param_decision_tree,\n",
        "                       cv = 5, verbose=2, scoring='r2')\n",
        "\n",
        "\n",
        "# Predict on the model\n",
        "decision_tree_grid.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "OnfstTkBgP8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing the best estimator from the grid search results\n",
        "best_decision_tree_model = decision_tree_grid.best_estimator_\n",
        "# The variable 'best_decision_tree_model' now contains the best decision tree model obtained from grid search\n"
      ],
      "metadata": {
        "id": "S7_tD0qqiCzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the best score obtained from the Decision Tree Grid Search\n",
        "print(\"Best Score (Decision Tree):\", decision_tree_grid.best_score_)\n",
        "\n"
      ],
      "metadata": {
        "id": "UM24lBi2iCuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best estimator (optimal model) from the grid search results for Decision Tree\n",
        "decision_tree_optimal_model = decision_tree_grid.best_estimator_\n",
        "\n",
        "# Use the optimal Decision Tree model to make predictions on the training data\n",
        "y_predict_train_decision_tree = decision_tree_optimal_model.predict(X_train)\n",
        "\n",
        "# Use the optimal Decision Tree model to make predictions on the test data\n",
        "y_predict_test_decision_tree = decision_tree_optimal_model.predict(X_test)\n",
        "\n",
        "# Now, y_predict_train_decision_tree contains the predicted labels for the training data\n",
        "# and y_predict_test_decision_tree contains the predicted labels for the test data\n",
        "# These predictions can be used for further evaluation or analysis\n"
      ],
      "metadata": {
        "id": "uzXo7eX7iCop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "s0X_7_algP8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "# evaluation metrics for train data set\n",
        "Regression_Metrics_Score_train['Decision Tree'] = regression_evaluation_metrics(X_train,Y_train,y_predict_train_decision_tree)\n",
        "\n",
        "# evaluation metrics for test data set\n",
        "Regression_Metrics_Score_test['Decision Tree'] = regression_evaluation_metrics(X_test,Y_test,y_predict_test_decision_tree)"
      ],
      "metadata": {
        "id": "xqSaeCYegP8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Regression_Metrics_Score_train"
      ],
      "metadata": {
        "id": "cmizBQMITmEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Regression_Metrics_Score_test"
      ],
      "metadata": {
        "id": "0GeA80IZVQKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion: Although this algorithm surpasses the linear regression, the accuracy score remains unsatisfactory(accuracy score: 44% train, 40% test)."
      ],
      "metadata": {
        "id": "8iSeEd6F50GA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model FOURTH - Random Forest.**"
      ],
      "metadata": {
        "id": "TeOezyPgkldZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary library for Random Forest Regressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Creating a RandomForestRegressor instance\n",
        "RFR = RandomForestRegressor()\n",
        "\n",
        "# At this point, RFR is an instance of the RandomForestRegressor class,\n",
        "# which can be further configured and trained using the fit() method.\n",
        "# You can set hyperparameters, specify features, and target variables,\n",
        "# and train the model using the fit() method to make predictions.\n"
      ],
      "metadata": {
        "id": "CCPEU4FeoJJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of trees in random forest\n",
        "n_estimators = [20,22,24]\n",
        "# number of feature to consider at every split\n",
        "max_features=[0.6]\n",
        "# maximum number of level in trees\n",
        "max_depth = [10,16]\n",
        "\n",
        "# number of samples\n",
        "max_samples = [0.75,1.0]\n",
        "\n",
        "# Hyperparameter Grid\n",
        "param_grid={'n_estimators' : n_estimators,\n",
        "            'max_depth': max_depth,\n",
        "            'max_features': max_features,\n",
        "            'max_samples': max_samples,\n",
        "                     }\n",
        "print(param_grid)"
      ],
      "metadata": {
        "id": "XCmMQoV6oJGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a GridSearchCV object with Random Forest Regressor, parameter grid, 2-fold cross-validation, and verbose output\n",
        "RF_grid = GridSearchCV(estimator=RFR, param_grid=param_grid, cv=2, verbose=2)"
      ],
      "metadata": {
        "id": "HJpIYJPnoJD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the GridSearchCV to the training data\n",
        "RF_grid.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "XmZQUXpMoJBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the best parameters found by the Random Forest Grid Search\n",
        "print(\"Best Parameters: \", RF_grid.best_params_)\n"
      ],
      "metadata": {
        "id": "13oevFN2oI-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specified during the Grid Search process.\n",
        "print(RF_grid.best_score_)"
      ],
      "metadata": {
        "id": "d-yFdSrMoI7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best estimator from the Random Forest grid search\n",
        "Random_Forest_optimal_model = RF_grid.best_estimator_\n",
        "\n",
        "# Use the trained Random Forest model to make predictions on the training data\n",
        "y_predict_train_Random_Forest = Random_Forest_optimal_model.predict(X_train)\n",
        "\n",
        "# Use the trained Random Forest model to make predictions on the test data\n",
        "y_predict_test_Random_Forest = Random_Forest_optimal_model.predict(X_test)\n",
        "\n",
        "# Here, X_train represents the feature matrix of the training data\n",
        "# X_test represents the feature matrix of the test data\n",
        "\n",
        "# 'Random_Forest_optimal_model' now contains the Random Forest model with the best hyperparameters\n",
        "# 'y_predict_train_Random_Forest' contains the predicted values for the training data\n",
        "# 'y_predict_test_Random_Forest' contains the predicted values for the test data\n"
      ],
      "metadata": {
        "id": "Yfa4FKF9oI36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation metrics for train data set\n",
        "Regression_Metrics_Score_train['Random Forest'] = regression_evaluation_metrics(X_train,Y_train,y_predict_train_Random_Forest)"
      ],
      "metadata": {
        "id": "8IC4p92ToI0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation metrics for test data set\n",
        "Regression_Metrics_Score_test['Random Forest'] = regression_evaluation_metrics(X_test,Y_test,y_predict_test_Random_Forest)"
      ],
      "metadata": {
        "id": "Lfo0WyiioIxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Regression_Metrics_Score_train"
      ],
      "metadata": {
        "id": "vyxk9DQyVYWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Regression_Metrics_Score_test"
      ],
      "metadata": {
        "id": "99sUY5DTVVSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This algorithm has performed a little better(accuracy score:60% train, 43% test)."
      ],
      "metadata": {
        "id": "9NJFgtlBOQWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model FIFTH - XG Boost**"
      ],
      "metadata": {
        "id": "ipQDdBHQ6tTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of Trees\n",
        "total_estimators = [50]\n",
        "\n",
        "# Maximum depth of trees\n",
        "max_depth_of_trees=[7,9]\n",
        "min_samples_split=[50]\n",
        "\n",
        "# learining rate=[0.1,0.3,0.5]\n",
        "\n",
        "# Hyperparameter Grid\n",
        "param_xgboost ={'total_estimators': total_estimators,\n",
        "                     'max_depth': max_depth,\n",
        "                     'min_samples_split': min_samples_split\n",
        "                     }"
      ],
      "metadata": {
        "id": "I-VEKzzWoIul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate XGRegressor\n",
        "import xgboost as xgb\n",
        "xgboost_model=xgb.XGBRegressor()\n",
        "\n",
        "# Grid search\n",
        "xgboost_grid=GridSearchCV(estimator=xgboost_model,param_grid=param_xgboost,cv=5,verbose=2,scoring='r2')\n",
        "xgboost_grid.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "AueKHpcgoIrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best cross-validation score achieved by the XGBoost model\n",
        "print(\"Best Cross-Validation Score: {:.2f}\".format(xgboost_grid.best_score_))\n"
      ],
      "metadata": {
        "id": "ouoAbyZpoIo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the best hyperparameters found by the grid search for the XGBoost model\n",
        "print(xgboost_grid.best_params_)\n"
      ],
      "metadata": {
        "id": "IGiRIYSKoImL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting the best XGBoost model obtained from the grid search\n",
        "# xgboost_grid: GridSearchCV object containing the results of the hyperparameter tuning\n",
        "# .best_estimator_: Attribute of GridSearchCV object, returns the best performing model\n",
        "\n",
        "xgboost_optimal_model = xgboost_grid.best_estimator_\n"
      ],
      "metadata": {
        "id": "_TA46pN6oIjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the target variable (y) for the test dataset using the trained XGBoost model\n",
        "y_pred_xgboost_test = xgboost_optimal_model.predict(X_test)\n",
        "\n",
        "# Predicting the target variable (y) for the training dataset using the trained XGBoost model\n",
        "y_pred_xgboost_train = xgboost_optimal_model.predict(X_train)\n",
        "\n",
        "# y_pred_xgboost_test now contains the predicted values for the test data\n",
        "# y_pred_xgboost_train now contains the predicted values for the training data\n",
        "# These predictions can be further used for evaluation or analysis purposes\n"
      ],
      "metadata": {
        "id": "3eR1pf_uoIgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for Train set\n",
        "Regression_Metrics_Score_train['XG Boost'] = regression_evaluation_metrics(X_train,Y_train,y_pred_xgboost_train)"
      ],
      "metadata": {
        "id": "96FyyBYSoIeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for Test set\n",
        "Regression_Metrics_Score_test['XG Boost'] = regression_evaluation_metrics(X_test,Y_test,y_pred_xgboost_test)"
      ],
      "metadata": {
        "id": "ZQZMOY5aoIbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This algorithm has given the best accuracy score till now (66% train,62% test) with low MSE."
      ],
      "metadata": {
        "id": "DnQ2jGBzgf4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "WgFwvPi_oIYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance=xgboost_optimal_model.feature_importances_\n",
        "importance"
      ],
      "metadata": {
        "id": "CCFCQck5hwLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imp_dict={'Feature' : list(X_train.columns),\n",
        "          'Feature Importance' : importance}\n",
        "importance_df = pd.DataFrame(imp_dict)"
      ],
      "metadata": {
        "id": "YnxpcbFkhwIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df.sort_values(by=['Feature Importance'],ascending=False,inplace=True)\n",
        "importance_df"
      ],
      "metadata": {
        "id": "5giNc2KjhwE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance plot\n",
        "plt.figure(figsize=(16,6))\n",
        "plt.title('Feature Importance')\n",
        "sns.barplot(x='Feature',y='Feature Importance',data=importance_df[:10])\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DG2k-j8fhwBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Regression_Metrics_Score_train"
      ],
      "metadata": {
        "id": "84Nw9dM9Vks0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Regression_Metrics_Score_test"
      ],
      "metadata": {
        "id": "4ihqzsHEVkgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Above algorithm has accuracy score:98% train, 30% test. which is lower that our previous algorithm (XG Boost).\n",
        "\n",
        "### **STEP 9 - Comparing evaluation metrics of different models.**"
      ],
      "metadata": {
        "id": "4pkb7bVkDHAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns"
      ],
      "metadata": {
        "id": "RhmObnag3rE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Regression_Metrics_Score_train = Regression_Metrics_Score_train.transpose()\n",
        "Regression_Metrics_Score_train"
      ],
      "metadata": {
        "id": "Nsjh7d953U55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Regression_Metrics_Score_test = Regression_Metrics_Score_test.transpose()\n",
        "Regression_Metrics_Score_test"
      ],
      "metadata": {
        "id": "NjCWkZSPZu6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Training Data\n",
        "#bar plot for R2 score\n",
        "fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize = (20, 5))\n",
        "x_ = ['Linear Regression', 'Gradientboost', 'Decision Tree', 'Random Forest', 'Xgboost']\n",
        "ax1.set_title('R2 Scores')\n",
        "ax = sns.barplot(x = x_, y ='R2 Score', data = Regression_Metrics_Score_train , ax = ax1)\n",
        "ax.set_xlabel('Models')\n",
        "ax.set_ylabel('R2 scores')\n",
        "\n",
        "# barplot for adjustedR2\n",
        "ax = sns.barplot(x = x_, y='Adjusted R2 Score',  data = Regression_Metrics_Score_train, ax = ax2)\n",
        "ax2.set_title('Adjusted R2 scores')\n",
        "ax.set_xlabel('Models')\n",
        "ax.set_ylabel('Adjusted R2 scores')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "d0fhyfYvBqex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Testing Data\n",
        "#bar plot for R2 score\n",
        "fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize = (20, 5))\n",
        "x_ = ['Linear Regression', 'Gradientboost', 'Decision Tree', 'Random Forest', 'Xgboost']\n",
        "ax1.set_title('R2 Scores')\n",
        "ax = sns.barplot(x = x_, y ='R2 Score', data = Regression_Metrics_Score_test , ax = ax1)\n",
        "ax.set_xlabel('Models')\n",
        "ax.set_ylabel('R2 scores')\n",
        "\n",
        "# barplot for adjustedR2\n",
        "ax = sns.barplot(x = x_, y='Adjusted R2 Score',  data = Regression_Metrics_Score_test, ax = ax2)\n",
        "ax2.set_title('Adjusted R2 scores')\n",
        "ax.set_xlabel('Models')\n",
        "ax.set_ylabel('Adjusted R2 scores')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GmzFW-Wag6AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The above graph clearly shows that Random forest has highest R2 scores and adjusted R2 score which suggest that it has better efficiency than other models."
      ],
      "metadata": {
        "id": "T9ETgMM6RDEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Training Data\n",
        "# Bar plot of MSE score\n",
        "fig,(ax1,ax2) = plt.subplots(ncols=2,figsize=(20,5))\n",
        "x_ = ['Linear Regression', 'Gradientboost','Decision Tree','Random Forest','XG Boost']\n",
        "ax1.set_title('MSE scores')\n",
        "ax = sns.barplot(x=x_,y='MSE',data=Regression_Metrics_Score_train,ax=ax1)\n",
        "ax.set_xlabel('Modles')\n",
        "ax.set_ylabel('MSE score')\n",
        "\n",
        "# Bar plot for RMSE score\n",
        "ax = sns.barplot(x=x_ , y='RMSE', data=Regression_Metrics_Score_train, ax=ax2)\n",
        "ax2.set_title('RMSE score')\n",
        "ax.set_xlabel('Modules')\n",
        "ax.set_ylabel('RMSE score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k7hGLWCPhvsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Testing Data\n",
        "# Bar plot of MSE score\n",
        "fig,(ax1,ax2) = plt.subplots(ncols=2,figsize=(20,5))\n",
        "x_ = ['Linear Regression', 'Gradientboost','Decision Tree','Random Forest','XG Boost']\n",
        "ax1.set_title('MSE scores')\n",
        "ax = sns.barplot(x=x_,y='MSE',data=Regression_Metrics_Score_test,ax=ax1)\n",
        "ax.set_xlabel('Modles')\n",
        "ax.set_ylabel('MSE score')\n",
        "\n",
        "# Bar plot for RMSE score\n",
        "ax = sns.barplot(x=x_ , y='RMSE', data=Regression_Metrics_Score_test, ax=ax2)\n",
        "ax2.set_title('RMSE score')\n",
        "ax.set_xlabel('Modules')\n",
        "ax.set_ylabel('RMSE score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vRMdJ1L_hGxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Only Random Forest has least errors, therefore it can be considered as good algorithm for training our model.\n",
        "\n",
        "\n",
        "### **Conclusion for EDA:**\n",
        "\n",
        "\n",
        "* Vendor 2 dominates the market, receiving a higher number of bookings compared to other vendors.\n",
        "\n",
        "* Analysis of daily pickup and dropoff patterns reveals that taxi booking rates significantly increase during weekends (Friday and Saturday). This uptick suggests a higher demand for taxi services during weekends, possibly due to social events, celebrations, or personal activities.\n",
        "* Observing monthly trends, it becomes evident that taxi reservations peak in March and April. Conversely, booking numbers decrease notably in January, February, and post-June.\n",
        "* Vendors experience their busiest months in March, with a decline in January, February, and after June, as per the monthly trend analysis.\n",
        "* Analyzing hourly pickup and dropoff patterns, it's apparent that taxis are frequently used for commuting to workplaces, especially after 10:00 AM. Additionally, demand surges in the late evening, particularly after 6:00 PM.\n",
        "* The majority of bookings are made by individual travelers, indicating a preference for solo rides. This implies a lower inclination towards carpooling, suggesting that people tend to travel alone rather than in groups.\n",
        "\n",
        "\n",
        "## **Conclusion for Model Training:**\n",
        "\n",
        "*We observed a significant presence of outliers in our dataset, with some values closely approaching zero. Attempts to remove these outliers led to substantial data loss. During the model training process, we experimented with various algorithms and achieved an accuracy level of 60%.\n",
        "\n",
        "*Concerns arose about potential overfitting of the model. Fortunately, our fears were dispelled as the model consistently produced similar results for both the training and test data across all algorithms tested. Notably, only two models, namely XG Boost and Random Forest, exhibited a remarkable alignment between the actual and predicted values, evidenced by their nearly overlapping lines in the graphs.\n",
        "\n",
        "*Additionally, we noticed that the R-squared (R2) scores were notably high, indicating the models' ability to explain the variance in the data. Moreover, the Mean Squared Error (MSE) scores were low for these models, meeting the criteria for a well-performing model.\n",
        "\n",
        "*Upon reflection, we realized that removing data led to a significant loss of valuable information. We also observed that introducing a new column, even if highly correlated with existing features, could yield seemingly favorable results (pseudo-good results). Furthermore, our Random Forest model provided the best R2 score. To prevent overfitting, we carefully tuned the model parameters, ensuring its stability and reliability in making predictions."
      ],
      "metadata": {
        "id": "Omg8LQu2UBIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Thankyou**"
      ],
      "metadata": {
        "id": "8FPwMCqfQxCA"
      }
    }
  ]
}